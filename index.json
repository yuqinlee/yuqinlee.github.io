[{"categories":["dev-env"],"content":"\r","date":"2024-06-22","objectID":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/:0:0","series":null,"tags":["docker","wsl","arch"],"title":"Windows 安装 Docker、wsl 等","uri":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/#"},{"categories":["dev-env"],"content":"\r安装 WSL——Archlinux控制面板找到 启用或关闭windows功能 勾选 Hyper-V 和 适用于 Linux 的 Windows 子系统（只用勾选后者实际就能WSL安装，如果需要使用原来的 Hyper-V 方式安装 Docker 才需要开启前者，这里直接都打开了），重启系统，执行 wsl --update 更新 安装 Archlinux 作为子系统 从 https://github.com/yuk7/ArchWSL/releases 下载压缩包 解压到指定目录 双击解压好的 Arch.exe 进行安装，这个 .exe 的名字 就是要创建的 WSL 实例的名字，改不同的名字就能创建多个 Arch WSL。 常用命令 bash wsl --list # 查看当前 wsl 中有的子系统 wsl --update # 下载或者更新 wsl --shutdown # 重新启动 wsl -d Arch # 进入名为 Arch 的子系统\r官网文档：https://learn.microsoft.com/zh-cn/windows/wsl/basic-commands 配置用户 bash passwd root useradd -m -G wheel -s /bin/bash uchin passwd uchin\r退出ArchLinux，进入刚刚安装ArchLinux的目录（例如D:\\vm\\archlinux），将默认用户改为非root用户： bash exit # 退出archlinux，之后你会回到Windows cd D:\\WSL\\Arch .\\Arch.exe config --default-user uchin\r配置hostname 参考：WSL设置hostname，不修改Windows主机名 默认的 /etc/ws.conf 如下 bash [uchin@DESKTOP-UCHIN ~]$ cat /etc/wsl.conf [boot] systemd=true [automount] enabled = true options = \"metadata\" mountFsTab = true\r该文件详细配置参考文档：https://learn.microsoft.com/zh-cn/windows/wsl/wsl-config bash [uchin@DESKTOP-UCHIN ~]$ cat /etc/wsl.conf [boot] systemd=true [automount] enabled = true options = \"metadata\" mountFsTab = true # 设置 wsl 自己的 hostname [network] generateResolvConf = true hostname = uchin-arch # 禁用 windows 环境变量 [interop] enabled = false appendWindowsPath = false\r","date":"2024-06-22","objectID":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/:1:0","series":null,"tags":["docker","wsl","arch"],"title":"Windows 安装 Docker、wsl 等","uri":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/#安装-wslarchlinux"},{"categories":["dev-env"],"content":"\r安装 docker","date":"2024-06-22","objectID":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/:2:0","series":null,"tags":["docker","wsl","arch"],"title":"Windows 安装 Docker、wsl 等","uri":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/#安装-docker"},{"categories":["dev-env"],"content":"\r安装这里使用 WSL2 的方式安装 Windows Docker WSL 对比 Hyper-V 体验更好，可以不考虑原来 Hyper-V 的方式了 运行 wsl --update，如果之前没更新会更新WSL，然后下载 Windows Docker https://www.docker.com/products/docker-desktop/ 安装时勾选 WSL2 安装即可安装完成 ","date":"2024-06-22","objectID":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/:2:1","series":null,"tags":["docker","wsl","arch"],"title":"Windows 安装 Docker、wsl 等","uri":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/#安装"},{"categories":["dev-env"],"content":"\r修改镜像位置默认安装 docker 后镜像存放路径为 C:\\Users\\uchin\\AppData\\Local\\Docker\\wsl 当镜像过多后会大量占用 C 盘 Docker Desktop WSL2 默认会安装2个子系统，使用命令wsl -l -v –all查看 bash C:\\Users\\uchin\u003ewsl -l -v --all NAME STATE VERSION * Arch Running 2 docker-desktop-data Running 2 docker-desktop Running 2\r两个子系统分别为 docker-desktop-data 与 docker-desktop docker-desktop-data 与 docker-desktop 前者存放数据，后者存放程序 bash # 1. 退出Docker Desktop # 2. 关闭 WSL wsl --shutdown # 3. 将子系统导出为 tar 文件 wsl --export docker-desktop D:\\WSL\\docker\\docker-desktop.tar wsl --export docker-desktop-data D:\\WSL\\docker\\docker-desktop-data.tar # 4. 注销子系统 wsl --unregister docker-desktop wsl --unregister docker-desktop-data # 5. 使用新路径导入子系统 wsl --import docker-desktop D:\\WSL\\docker\\docker-desktop D:\\WSL\\docker\\docker-desktop.tar --version 2 wsl --import docker-desktop-data D:\\WSL\\docker\\docker-desktop-data D:\\WSL\\docker\\docker-desktop-data.tar --version 2\r参考： √ Arch WSL 安装 1 √ Arch WSL 安装 2 × Arch WSL appx 安装方式 √ windows docker 安装 √ Docker Desktop(WSL2)修改镜像存储位置 √ ls 命令输出的颜色 √ 系统配置bash shell字体颜色 Linux PS1 的常用配置 √ 通过 VcXsrv 在 WSL2 上使用图形化界面 √ 使用 WSL2 + X11 转发 - 在 Windows10 中打造 GNU/Linux 学习生产环境 ","date":"2024-06-22","objectID":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/:3:0","series":null,"tags":["docker","wsl","arch"],"title":"Windows 安装 Docker、wsl 等","uri":"/windows-%E5%AE%89%E8%A3%85-dockerwsl-%E7%AD%89/#修改镜像位置"},{"categories":["linux"],"content":"\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:0:0","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#"},{"categories":["linux"],"content":"\r1. 无图形安装","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:0","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#1-无图形安装"},{"categories":["linux"],"content":"\r检查安装模式检测是否为 uefi 方式 安装，若为 uefi 方式 则以下命令将输出一堆东西 bash ls /sys/firmware/efi/efivars\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:1","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#检查安装模式"},{"categories":["linux"],"content":"\r更改字体默认 liveCD 字体可能过小 bash setfont /usr/local/kbd/consolefonts/LatGrkCyr-12x22.psfu.gz\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:2","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#更改字体"},{"categories":["linux"],"content":"\r禁用 reflector 服务禁用 reflector 服务，以方便自定义源 bash systemctl stop reflector.service\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:3","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#禁用-reflector-服务"},{"categories":["linux"],"content":"\r设置镜像源\rbash vim /etc/pacman.d/mirrorlist\r生效的是首行，因此添加中科大或者清华的放在最上面 text Server = https://mirrors.ustc.edu.cn/archlinux/$repo/os/$arch Server = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:4","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#设置镜像源"},{"categories":["linux"],"content":"\r连接网络\rbash iwctl # 执行iwctl命令，进入交互式命令行 device list # 列出设备名，比如无线网卡看到叫 wlan0 station wlan0 scan # 扫描网络 station wlan0 get-networks # 列出网络 比如想连接YOUR-WIRELESS-NAME这个无线 station wlan0 connect YOUR-WIRELESS-NAME # 进行连接 输入密码即可 exit # 成功后exit退出\r设置完成后测试 bash ping baidu.com\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:5","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#连接网络"},{"categories":["linux"],"content":"\r更新系统时钟\rbash timedatectl set-ntp true # 将系统时间与网络时间进行同步 timedatectl status # 检查服务状态\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:6","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#更新系统时钟"},{"categories":["linux"],"content":"\r分区（Btrfs）这里文件采用 Btrfs 文件系统，分区根据个人情况 / /home /efi Swap 500M \u003e= 内存 x 60% 由于使用 Btrfs 文件系统，这里 /home 与 / 将位于同一分区 bash lsblk # 显示当前分区情况 cfdisk /dev/sdx # 对安装 archlinux 的磁盘分区 fdisk -l # 分区完成后复查磁盘情况\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:7","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#分区btrfs"},{"categories":["linux"],"content":"\r格式化\rbash mkfs.vfat /dev/sdax # 格式化 efi 分区 mkfs.btrfs -L myArch /dev/sdxn # 格式化 / 与 /home 所在分区 mkswap /dev/sdxn # 格式化 Swap 分区\r双系统中原本 Windows 已经存在 efi 分区的情况下，不需要再格式化了，后续挂载即可 ","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:8","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#格式化"},{"categories":["linux"],"content":"\r创建子卷为创建子卷，先将 / 与 /home 所在分区挂载至 /mnt bash mount -t btrfs -o compress=zstd /dev/sdxn /mnt\rbash df -h # 查看挂载状态\rbash btrfs subvolume create /mnt/@ # 创建 / 目录子卷 btrfs subvolume create /mnt/@home # 创建 /home 目录子卷\r查看子卷情况 bash btrfs subvolume list -p /mnt\r子卷创建完成后卸载 bash umount /mnt\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:9","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#创建子卷"},{"categories":["linux"],"content":"\r挂载先挂根目录 bash mount -t btrfs -o subvol=/@,compress=zstd /dev/sdxn /mnt # 挂载 / 目录 mkdir /mnt/home # 创建 /home 目录 mount -t btrfs -o subvol=/@home,compress=zstd /dev/sdxn /mnt/home # 挂载 /home 目录 mkdir -p /mnt/boot/efi # 创建 /boot/efi 目录 mount /dev/sdxn /mnt/boot/efi # 挂载 /boot/efi 目录 swapon /dev/sdxn # 挂载交换分区\r查看挂载情况 bash df -h free -h # 查看 Swap 情况\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:10","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#挂载"},{"categories":["linux"],"content":"\r安装\rbash pacstrap /mnt base base-devel linux linux-firmware pacstrap /mnt dhcpcd iwd vim\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:11","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#安装"},{"categories":["linux"],"content":"\r生成 fstab 文件\rbash genfstab -U /mnt \u003e /mnt/etc/fstab cat /mnt/etc/fstab # 复查一下 /mnt/etc/fstab 确保没有错误\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:12","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#生成-fstab-文件"},{"categories":["linux"],"content":"\r切换系统\rbash arch-chroot /mnt\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:13","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#切换系统"},{"categories":["linux"],"content":"\r主机与主机名\rbash vim /etc/hostname # 修改主机名 vim /etc/hosts # 修改主机映射\rbash # /etc/hosts 127.0.0.1 localhost ::1 localhost 127.0.1.1 myarch.localdomain myarch\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:14","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#主机与主机名"},{"categories":["linux"],"content":"\r时间与时区\rbash ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #设置时区 hwclock --systohc # 硬件时间设置\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:15","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#时间与时区"},{"categories":["linux"],"content":"\rLocale编辑 /etc/locale.gen，去掉 en_US.UTF-8 UTF-8 以及 zh_CN.UTF-8 UTF-8 行前的注释符号 # bash vim /etc/locale.gen # 去除相关注释 locale-gen # 生成 locale echo 'LANG=en_US.UTF-8' \u003e /etc/locale.conf # 向 /etc/locale.conf 导入内容\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:16","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#locale"},{"categories":["linux"],"content":"\r安装微码\rbash pacman -S intel-ucode # Intel pacman -S amd-ucode # AMD\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:17","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#安装微码"},{"categories":["linux"],"content":"\r引导\rbash # 安装引导程序相应包 pacman -S grub efibootmgr os-prober # 安装 GRUB 到 EFI 分区 grub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=ARCH # 编辑 /etc/default/grub 文件 vim /etc/default/grub 找到 GRUB_CMDLINE_LINUX_DEFAULT 这一行，进行如下修改： 去掉这行中最后的 quiet 参数 把 loglevel 的数值从 3 改成 5。这样是为了后续如果出现系统错误，方便排错 加入 nowatchdog 参数，这可以显著提高开关机速度 添加新的一行 GRUB_DISABLE_OS_PROBER=false 修改后为： bash # GRUB boot loader configuration GRUB_DEFAULT=0 GRUB_TIMEOUT=5 GRUB_DISTRIBUTOR=\"Arch\" GRUB_CMDLINE_LINUX_DEFAULT=\"loglevel=5 nowatchdog\" GRUB_CMDLINE_LINUX=\"\" GRUB_DISABLE_OS_PROBER=false ...\r生成 GRUB 所需的配置文件,若引导了 Windows 将会有相应输出 bash grub-mkconfig -o /boot/grub/grub.cfg\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:18","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#引导"},{"categories":["linux"],"content":"\r设置root 密码\rbash passwd root\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:1:19","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#设置root-密码"},{"categories":["linux"],"content":"\r2. 基础配置","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:2:0","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#2-基础配置"},{"categories":["linux"],"content":"\r添加用户添加用户，比如新增加的用户叫 testuser bash useradd -m -G wheel -s /bin/bash uchin #wheel附加组可sudo，以root用\r户执行命令 -m同时创建用户家目录 设置新用户 testuser 的密码 bash passwd uchin\r编辑 sudoers 配置文件 bash EDITOR=vim visudo # 需要以 root 用户运行 visudo 命令\r找到下面这样的一行，把前面的注释符号 # 去掉，:wq 保存并退出即可。 bash # %wheel ALL=(ALL) ALL\r这里稍微解释一下 %wheel 代表是 wheel 组，百分号是前缀 ALL= 代表在所有主机上都生效(如果把同样的sudoers文件下发到了多个主机上) (ALL) 代表可以成为任意目标用户 ALL 代表可以执行任意命令 一个更详细的例子: bash %mailadmin snow,rain=(root) /usr/sbin/postfix, /usr/sbin/postsuper, /usr/bin/doveadm nobody ALL=(root) NOPASSWD: /usr/sbin/rndc reload\r组 mailadmin 可以作为 root 用户，执行一些邮件服务器控制命令。可以在 “snow” 和 “rain\"这两台主机上执行 用户 nobody 可以以 root 用户执行rndc reload命令。可以在所有主机上执行。同时可以不输入密码。(正常来说 sudo 都是要求输入调用方的密码的) ","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:2:1","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#添加用户"},{"categories":["linux"],"content":"\r图形界面\rbash sudo pacman -S xorg sudo pacman -S xorg-server\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:2:2","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#图形界面"},{"categories":["linux"],"content":"\r3. DWM","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:3:0","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#3-dwm"},{"categories":["linux"],"content":"\r基础安装与启动没联网先联网，同前文使用 iwd 方式连接，没开服务先开服务 bash systemctl enable dhcpcd # 开机自启 dhcp systemctl start iwd.service # 开启 iwd 服务 iwctl # 联网 ···\r若没安装 xorg 组件，先安装 bash sudo pacman -S xorg-server sudo pacman -S xorg-apps sudo pacman -S xorg-xinit\r中文字体未安装先安装 bash sudo pacman -S noto-fonts-cjk #安装中日韩字体，避免不能正常显示\r下载所需要的包 bash git clone https://git.suckless.org/dwm\r安装 bash sudo make clean install\r修改 ~/.xinitrc bash # ~/.xinitrc exec dwm\r启动 bash startx\r","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:3:1","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#基础安装与启动"},{"categories":["linux"],"content":"\r打 patchto be contiune ","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:3:2","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#打-patch"},{"categories":["linux"],"content":"\r4. Awesome 安装awesome bash pacman -S awesome\r安装字体 bash sudo pacman -S adobe-source-han-serif-cn-fonts wqy-zenhei #安装几个开源中文字体 一般装上文泉驿就能解决大多wine应用中文方块的问题 sudo pacman -S noto-fonts-cjk noto-fonts-emoji noto-fonts-extra 输入法问题 wiki 来自blibili的配置 https://manateelazycat.github.io/linux/2020/06/19/fcitx5-is-awesome.html rofi Rofi 配置 安装 Arch Linux 安装使用教程 archlinux 简明指南 DWM suckless.org yaocccc-bilibli Arch Linux 美化 (st + dwm) DWM安装及简略配置教程 yaocccc-github 在Arch上使用Fcitx5 TheCW-bilibili theniceboy的脚本 输入法 Arch系安装并配置fcitx5输入法 其他 archlinux 修复uefi引导启动 流行终端对比 Kitty Terminal 终端 kitty文档 ","date":"2023-02-01","objectID":"/archlinux-%E7%AE%80%E8%AE%B0/:4:0","series":null,"tags":["linux","arch","dwm","awesome"],"title":"Archlinux 简记","uri":"/archlinux-%E7%AE%80%E8%AE%B0/#4-awesome"},{"categories":["distributed system"],"content":"\r","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:0:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#"},{"categories":["distributed system"],"content":"\r1. 序","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:1:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#1-序"},{"categories":["distributed system"],"content":"\r1.1 各虚拟机信息 CentOS 7 VirtualBox 虚拟机名 虚拟磁盘大小 IP Host映射 myCent_00 100G 192.168.56.101 master myCent_01 50G 192.168.56.104 slave01 myCent_02 50G 192.168.56.103 slave02 注：各虚拟机节点网卡设置如下 Nat：负责虚拟机与外网链接，保持默认 Host-Only：设置静态 ip 保证集群之间通信 确保每台虚拟机能 ping 通外网网络设置好后，更改主机名与映射，主机名修改后重启生效 bash vim /etc/hostname #修改主机名 vim /etc/hosts # 修改映射\r修改后如下： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:1:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#11-各虚拟机信息"},{"categories":["distributed system"],"content":"\r1.2 ssh 免密登录注：免密登录配置的为各节点的 hadoop 用户 以 master 节点为例，生成公钥、修改权限等命令如下 bash cd ~ mkdir .ssh cd .ssh # rm ./* # 删除当前目录下所有内容（首次配置时该目录下无内容，不用删除） ssh-keygen -t rsa # 生成公钥 cat ./id_rsa.pub \u003e\u003e ./authorized_keys # 添加至认证文件 chmod 700 ~/.ssh/ # 赋予.ssh文件700权限,有的机器必须，但有的是可选 chmod 600 ./authorized_keys # 赋予认证文件600权限 ssh localhost # 测试\r退出登录执行 exit 即可，至此 master 节点上公钥、文件权限修改完成，要使得 master 能免密登录其他节点，将 master 的公钥传给其他节点，并让其追加至认证文件即可 即：要免密登录谁，就将自己的公钥给他，让他写入认证文件 authorized_keys 中 发送 master 的公钥至 slave01 节点 bash cd ~.ssh scp ./id_rsa.pub slave01:~/.ssh/id_master 登录至 slave01 ，将 master 的公钥追加到认证文件，其他节点类似 bash cd ~/.ssh cat ./id_master \u003e\u003e ./authorized_keys chmod 700 ~/.ssh/ # 赋予.ssh文件700权限,有的机器必须，但有的是可选 chmod 600 ./authorized_keys # 赋予认证文件600权限\r","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:1:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#12-ssh-免密登录"},{"categories":["distributed system"],"content":"\r1.3 CentOS 安装 Docker\r1.3.1 安装 更新 yum bash sudo yum -y update\r添加源，选一个即可，考虑国内网络，这里使用的是阿里的源 bash # 阿里仓库 sudo yum-config-manager --add-repo http://mirrors. aliyun.com/docker-ce/linux/centos/docker-ce.repo # 中央仓库 # sudo yum-config-manager --add-repo http://download. docker.com/linux/centos/docker-ce.repo\r注：这里没有添加源的话，yum 默认是没有 docker 的包安装的 查看可用版本 bash yum list docker-ce --showduplicates | sort -r\r安装 bash sudo yum -y install docker-ce-18.03.1.ce\r安装完成如图 1.3.2 更改用户组 查看用户组命令 bash groups hadoop # hadoop : hadoop docker\r创建 docker 用户组，添加当前用户 在安装完 docker 后默认会创建 docker 用户组 bash sudo groupadd docker # 新建 docker 组 sudo usermod -aG docker $USER # 添加当前用户至docker组 newgrp docker #更新\r执行更新命令后就不会再出现 Got permission denied while trying to connect to the Docker daemon socket... 报错了，或者修改用户组后退出当前终端并重新登录进行测试 docker 启动重启等相关命令 这里启动 docker 服务并设置开机自启即可，执行以下命令前两条 bash # 启动 docker systemctl start docker # 设置开机自启 systemctl enable docker # 设置开机自启并立即启动docker服务（相当于以上两条命令都执行） systemctl enable --now docker # 重启docker systemctl restart docker # 停止docker systemctl stop docker # 移除开机自启 systemctl disable docker\r测试安装是否成功 bash docker run --rm hello-world\r注：首次执行需要拉去镜像，会花一段时间 在准备创建集群的各节点安装 docker，操作同上 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:1:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#13-centos-安装-docker"},{"categories":["distributed system"],"content":"\r1.3 CentOS 安装 Docker\r1.3.1 安装 更新 yum bash sudo yum -y update\r添加源，选一个即可，考虑国内网络，这里使用的是阿里的源 bash # 阿里仓库 sudo yum-config-manager --add-repo http://mirrors. aliyun.com/docker-ce/linux/centos/docker-ce.repo # 中央仓库 # sudo yum-config-manager --add-repo http://download. docker.com/linux/centos/docker-ce.repo\r注：这里没有添加源的话，yum 默认是没有 docker 的包安装的 查看可用版本 bash yum list docker-ce --showduplicates | sort -r\r安装 bash sudo yum -y install docker-ce-18.03.1.ce\r安装完成如图 1.3.2 更改用户组 查看用户组命令 bash groups hadoop # hadoop : hadoop docker\r创建 docker 用户组，添加当前用户 在安装完 docker 后默认会创建 docker 用户组 bash sudo groupadd docker # 新建 docker 组 sudo usermod -aG docker $USER # 添加当前用户至docker组 newgrp docker #更新\r执行更新命令后就不会再出现 Got permission denied while trying to connect to the Docker daemon socket... 报错了，或者修改用户组后退出当前终端并重新登录进行测试 docker 启动重启等相关命令 这里启动 docker 服务并设置开机自启即可，执行以下命令前两条 bash # 启动 docker systemctl start docker # 设置开机自启 systemctl enable docker # 设置开机自启并立即启动docker服务（相当于以上两条命令都执行） systemctl enable --now docker # 重启docker systemctl restart docker # 停止docker systemctl stop docker # 移除开机自启 systemctl disable docker\r测试安装是否成功 bash docker run --rm hello-world\r注：首次执行需要拉去镜像，会花一段时间 在准备创建集群的各节点安装 docker，操作同上 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:1:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#131-安装"},{"categories":["distributed system"],"content":"\r1.3 CentOS 安装 Docker\r1.3.1 安装 更新 yum bash sudo yum -y update\r添加源，选一个即可，考虑国内网络，这里使用的是阿里的源 bash # 阿里仓库 sudo yum-config-manager --add-repo http://mirrors. aliyun.com/docker-ce/linux/centos/docker-ce.repo # 中央仓库 # sudo yum-config-manager --add-repo http://download. docker.com/linux/centos/docker-ce.repo\r注：这里没有添加源的话，yum 默认是没有 docker 的包安装的 查看可用版本 bash yum list docker-ce --showduplicates | sort -r\r安装 bash sudo yum -y install docker-ce-18.03.1.ce\r安装完成如图 1.3.2 更改用户组 查看用户组命令 bash groups hadoop # hadoop : hadoop docker\r创建 docker 用户组，添加当前用户 在安装完 docker 后默认会创建 docker 用户组 bash sudo groupadd docker # 新建 docker 组 sudo usermod -aG docker $USER # 添加当前用户至docker组 newgrp docker #更新\r执行更新命令后就不会再出现 Got permission denied while trying to connect to the Docker daemon socket... 报错了，或者修改用户组后退出当前终端并重新登录进行测试 docker 启动重启等相关命令 这里启动 docker 服务并设置开机自启即可，执行以下命令前两条 bash # 启动 docker systemctl start docker # 设置开机自启 systemctl enable docker # 设置开机自启并立即启动docker服务（相当于以上两条命令都执行） systemctl enable --now docker # 重启docker systemctl restart docker # 停止docker systemctl stop docker # 移除开机自启 systemctl disable docker\r测试安装是否成功 bash docker run --rm hello-world\r注：首次执行需要拉去镜像，会花一段时间 在准备创建集群的各节点安装 docker，操作同上 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:1:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#132-更改用户组"},{"categories":["distributed system"],"content":"\r2. Docker 网络基础","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:2:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#2-docker-网络基础"},{"categories":["distributed system"],"content":"\r2.1 基本原理 每启动一个 docker，docker 就会给容器分配一个 ip，只要安装了 docker，就会有一个 docker0 的网卡，这里的网卡采用的是桥接模式，使用的技术是 evth-pair 技术 当启动一个容器时，本地就会多一个网卡（与容器的网卡成对） 这些由于容器而产生的成对的网卡就是 evth-pair 技术：一对虚拟设备接口，一端连着协议，一端彼此连接 正因为有这个特性，evth-pair 充当一个桥梁，连接各种虚拟设备 因此容器之间也是可以 ping 通的 所有容器在没有指定网络的情况下都是 docker0 进行路由的，docker 会给容器分配默认的可用 ip –link 有待学习 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:2:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#21-基本原理"},{"categories":["distributed system"],"content":"\r2.2 自定义网络Docker 有以下四种网络模式 bridge：桥接（默认方式） none：不配置网络 host：和宿主机共享网络 container：容器内网络连通（用的少） bash docker run -it -P --name mycentos centos # docker run -it -P --name mycentos --net bridge centos 上述两个命令等价，因为默认创建就是使用的 bridge docker0 特点：默认的，但是域名不能访问，使用 --link 可以打通连接 –link 有待学习 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:2:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#22-自定义网络"},{"categories":["distributed system"],"content":"\r2.3 常用命令Docker network 子命令如下： bash docker network create # 创建网络 docker network connect # 连接 docker network ls # 列出网络 docker network rm # 删除网络 docker network disconnect # 断开连接 docker network inspect # 列出某网络详细信息\r","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:2:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#23-常用命令"},{"categories":["distributed system"],"content":"\r3. Docker 数据卷","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:3:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#3-docker-数据卷"},{"categories":["distributed system"],"content":"\r3.1 基本挂载命令使用 -v 命令挂载 bash docker run -it -v 主机目录:容器内目录\r-v 后进行的目录映射，类似于端口映射 -p 主机端口:容器内端口 bash docker run -it -v /home/hadoop/utest/test_docker_volume/:/home centos /bin/bash\r这样，当在容器内部指定的目录内创建文件、文件夹等操作后会与主机对应的目录同步；同样的，在主机相应的目录中的操作也会同步到容器的响应目录中，这样当容器关闭后数据就能保存下来 当需要挂载多个目录时可使用多个 -v 参数，例如 bash docker run -d -p 3310:3306 -v /home/hadoop/utest/test_docker_volume/mysql/conf:/etc/mysql/conf.d -v /home/hadoop/utest/test_docker_volume/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql\r以上 -e 是指定环境，这里指定了密码 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:3:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#31-基本挂载命令"},{"categories":["distributed system"],"content":"\r3.2 具名挂载与匿名挂载以上挂载时，指定了主机内对应的映射，如果不指定主机的目录，只在 -v 后声明容器内要被映射的目录，那就是匿名挂载，例如 bash docker run -d -P --name nginx01 -v /etc/nginx nginx\r-P 是随机端口映射 上述挂载就至指定了容器内的目录 使用 bash docker volume ls\r查看所有卷 txt (base) [hadoop@master test_docker_volume]$ docker volume ls DRIVER VOLUME NAME local 137b54d6bf243bdd8d87e89f991597ca283780e1396d9fc7ec32623362cbdb8e local 441ffaf533e1a0c851f59690a287fc28aa85df60a7ad352c5d98cdc5680f2ddf local b63721368502cc85d467e02fa2a7189f25c8a509553c23155e81947402ecf2a2 local portainer_data\r上述前三条就是匿名挂载，如果在 -v 后指定卷名，那就是具名挂载，例如 bash docker run -it -v juming:/home centos /bin/bash\r使用 docker volume inspect 卷名 查看该卷 txt (base) [hadoop@master run]$ docker volume inspect juming [ { \"CreatedAt\": \"2022-04-26T15:04:52+08:00\", \"Driver\": \"local\", \"Labels\": null, \"Mountpoint\": \"/var/lib/docker/volumes/juming/_data\", \"Name\": \"juming\", \"Options\": null, \"Scope\": \"local\" } ] (base) [hadoop@master run]$ 可以看到该卷在主机上的挂载点为 /var/lib/docker/volumes/juming/_data 所有的 docker 容器卷，在没有指定目录的情况下都是在 /var/lib/docker/volumes/xxx/_data 处，其中 xxx 是卷名，_data 下放数据 通过具名挂载可以很方便找到一个卷，大多数时候都使用具名挂载 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:3:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#32-具名挂载与匿名挂载"},{"categories":["distributed system"],"content":"\r3.3 控制权限\rbash docker run -it -v juming:/home:ro centos /bin/bash docker run -it -v juming:/home:rw centos /bin/bash\r上述添加了 ro、rw 分别表示只读与可读写，一旦设定了只读，那说明这个目录只能通过宿主机来进行改变，容器内部是无法操作的 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:3:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#33-控制权限"},{"categories":["distributed system"],"content":"\r3.4 dockerfile 与数据卷 创建 dockerfile dockerfile FROM centos VOLUME [\"volume01\",\"volume02\"] CMD echo \"--------- end ---------\" CMD /bin/bash\r这里的每个命令就是镜像的一层，这里通过生成镜像的方式使得在容器创建时候就挂载不需要再指定参数 构建 bash docker build -f dockerfile1 -t uchin_centos .\r上述 -f 指定 dockerfile 文件，-t 即 target，指定生成的镜像名，最后指定生成后的路径 txt (base) [hadoop@master test_docker_volume]$ docker build -f dockerfile1 -t uchin_centos . Sending build context to Docker daemon 2.048kB Step 1/4 : FROM centos ---\u003e 5d0da3dc9764 Step 2/4 : VOLUME [\"volume01\",\"volume02\"] ---\u003e Running in 8ce46c7e7766 Removing intermediate container 8ce46c7e7766 ---\u003e 3019041d4948 Step 3/4 : CMD echo \"--------- end ---------\" ---\u003e Running in b4647234f83d Removing intermediate container b4647234f83d ---\u003e b61a9aa5313f Step 4/4 : CMD /bin/bash ---\u003e Running in 8669d24b2112 Removing intermediate container 8669d24b2112 ---\u003e 8ea7424ac06e Successfully built 8ea7424ac06e Successfully tagged uchin_centos:latest (base) [hadoop@master test_docker_volume]$ docker image ls | grep uchin_centos uchin_centos latest 8ea7424ac06e 2 minutes ago 231MB\r测试 bash docker run -it uchin_centos /bin/bash\r进入容器后发现指定的数据卷就被自动挂载了 txt [root@5a1789b7990c /]# ls -l | grep volume drwxr-xr-x. 2 root root 6 Apr 26 07:36 volume01 drwxr-xr-x. 2 root root 6 Apr 26 07:36 volume02\r并且这个卷和外部是同步的，但是在 dockerfile 中使用的是匿名挂载的方式，可以使用 inspect 方式查询其具体位置 这种方式使用十分多，通常我们都会自己构建镜像，假设构建镜像时没有挂载卷，就手动使用 -v 方式挂载 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:3:4","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#34-dockerfile-与数据卷"},{"categories":["distributed system"],"content":"\r3.5 数据卷容器 创建父容器 bash docker run -it --name docker01 uchin_centos /bin/bash\r在创建一个，使用 --volumes-from 参数来实现数据卷的共享 bash docker run -it --name docker02 --volumes-from docker01 uchin_centos /bin/bash\r这样挂载的数据卷就可以实现多容器的共享了，当然这里不使用相同的镜像也可以 有待继续探究 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:3:5","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#35-数据卷容器"},{"categories":["distributed system"],"content":"\r4. Docker Dokcerfile","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:4:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#4-docker-dokcerfile"},{"categories":["distributed system"],"content":"\r4.1 前言Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 当获取的镜像不满足我们使用的需求时，往往需要在创建容器后，自己再在容器中执行命令去安装软件、配置文件等。当多次需要使用到相同环境时这样不方便。 可以使用docker commit命令将已经配置好的容器提交为镜像类似于git的提交，这是一种手动保存镜像的方式，这里的 Dockerfile 就是一种更加自动化的方式去进行镜像的构建 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:4:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#41-前言"},{"categories":["distributed system"],"content":"\r4.2 Dokcerfile 构建使用 Dockerfile 构建一个镜像流程 创建一个目录并进入其中（以下均在该目录下进行） 新建一个名为 Dockerfile 文件，并定义指令（见下节） 在 Dockerfile 文件的存放目录下，执行构建动作 docker build -t mycentos:v1 .命令构建 其中 -t 即 target，参数指定 镜像名称:镜像标签； . 代表本次执行的上下文路径 上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。 解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。 如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。 注意：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:4:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#42-dokcerfile-构建"},{"categories":["distributed system"],"content":"\r4.3 Dockerfile 指令以下为一个 Dockerfile 文件示例 Dockerfile FROM python:3.7-alpine WORKDIR /code ENV FLASK_APP=app.py ENV FLASK_RUN_HOST=0.0.0.0 RUN apk add --no-cache gcc musl-dev linux-headers COPY requirements.txt requirements.txt RUN pip install -r requirements.txt EXPOSE 5000 COPY . . CMD [\"flask\", \"run\"]\rFROM：定制的镜像都是基于 FROM 的镜像，这里的 python:3.7-alpine 就是定制需要的基础镜像。后续的操作都是基于 python:3.7-alpine RUN：用于执行后面跟着的命令行命令。有以下两种格式： bash RUN \u003c命令行命令\u003e RUN [\"可执行文件\", \"参数1\", \"参数2\"] # 例如： # RUN [\"./test.php\", \"dev\", \"offline\"] 等价于 RUN ./test.php dev offline\r注：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大，尽量使用 \u0026\u0026 符号将多个命令写成一行，这样就只会创建一层镜像，例如 RUN yum -y install wget \\\r\u0026\u0026 wget -O redis.tar.gz \"http://download.redis.io/releases/redis-5.0.3.tar.gz\" \\\r\u0026\u0026 tar -xvf redis.tar.gz 更多指令参考https://www.runoob.com/docker/docker-dockerfile.html ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:4:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#43-dockerfile-指令"},{"categories":["distributed system"],"content":"\r5. Docker compose","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:5:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#5-docker-compose"},{"categories":["distributed system"],"content":"\r5.1 前言原先是使用 dockerfile 进行镜像创建，使用docker build、docker run 等命令进行手动的操作单个容器；这样也不便实现相互之间的依赖关系，于是就有了 docker compose 这一容器编排管理技术 使用docker compose 能高效管理容器： ① 定义多个运行容器 ② 实现批量容器编排 使用步骤: dockerfile：确保项目在任何地方都可以运行 docker-compose.yml：定义服务 docker-compose up：运行 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:5:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#51-前言"},{"categories":["distributed system"],"content":"\r5.2 安装docker compose 不是 docker 所自带，需要额外自行安装 注：在使用 swarm 集群时，使用 docker stack deploy 指定 compose 文件进行构建时没有安装 docker-compose 也可以 下载 bash sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose # sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` \u003e /usr/local/bin/docker-compose\r赋权限 bash sudo chmod +x /usr/local/bin/docker-compose\r","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:5:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#52-安装"},{"categories":["distributed system"],"content":"\r5.3 测试注：测试来源于 docker 官网 创测试目录 bash mkdir composetest cd composetest\r创建 app.py python import time import redis from flask import Flask app = Flask(__name__) cache = redis.Redis(host='redis', port=6379) def get_hit_count(): retries = 5 while True: try: return cache.incr('hits') except redis.exceptions.ConnectionError as exc: if retries == 0: raise exc retries -= 1 time.sleep(0.5) @app.route('/') def hello(): count = get_hit_count() return 'Hello World! I have been seen {} times.\\n'.format(count)\rDockerfile dockerfile FROM python:3.7-alpine WORKDIR /code ENV FLASK_APP=app.py ENV FLASK_RUN_HOST=0.0.0.0 RUN apk add --no-cache gcc musl-dev linux-headers COPY requirements.txt requirements.txt RUN pip install -r requirements.txt EXPOSE 5000 COPY . . CMD [\"flask\", \"run\"]\rdocker-compose.yml 文件 yaml version: \"3.9\" services: web: build: . ports: - \"8000:5000\" redis: image: \"redis:alpine\"\r运行 bash docker-compose up\r创建步骤： 应用 app.py Dockerfile 使应用能打包为镜像 docker-compose 文件（定义整个服务，需要的环境，web、redis）提供完整的上线服务 启动 compose 项目（docker-compose up） 注：这里的 web 服务所使用的镜像是使用 Dockerfile 进行 build 的；而 redis 服务是直接使用的镜像，两种方式都可，但是在 swarm 集群中是不能通过 build 来进行镜像的创建的 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:5:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#53-测试"},{"categories":["distributed system"],"content":"\r5.4 compose 配置规则详细配置可参考官网 一般使用的 compose 文件包含以下三大部分： yaml # 1. 版本 version: \"3.9\" # 2. 定义服务 services: 服务1（web）: 服务配置（image、build、network）: 服务2（redis）: 服务3: # 3. 其他配置（网络、卷、全局规则） volumes: networks: configs:\r有时其他配置可不需要 注：集群中使用 compose 配置进行服务的创建有所不同，具体参考下文 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:5:4","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#54-compose-配置规则"},{"categories":["distributed system"],"content":"\r6. Swarm 集群部署进行 swarm 集群搭建前请确保 各节点之间能通讯正常 能通过相互免密登录 docker 均已安装其能正常使用 注：以下操作都在各节点的 hadoop 用户下操作，集群部署使用的用户名保持各节点一致 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:6:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#6-swarm-集群部署"},{"categories":["distributed system"],"content":"\r6.1 集群创建如有多块网卡，需指定集群中使用的网卡所对应的 ip，例如，当前有多块网卡，如下图 这里将 enp0s9 作为集群通信所使用的，那就用其所对应ip 192.168.56.101 选择一个节点作为 manager 节点登录，执行初始化命令 bash docker swarm init --autolock=false --advertise-addr 192.168.56.101 --listen-addr 192.168.56.101:2377 执行后如下 初始化后，当前所在的这个节点就是 manager，接下来可添加 worker,复制以上 Join token 内容，即 docker swarm join --token SWMTKN-1-5tquxa6ztsbln9l4q0gr5tq6o7wowj16oncu6vg9t26mp9shj7-drdzg6xreehoz3gpm6h48hgpk 192.168.56.101:2377 ，登录 slave01 节点，执行该命令，即可将 slave01 节点以 worker 方式加入 swarm 集群 在 swarm 中有两种可用的不同的 token，一种是用作worker角色，另一个是用作manager角色 由于集群中允许有多个 manager 与 worker 的存在，因此在 join 时根据所使用的 token 的不同，加入的方式也不同，如果使用的是 worker 的 token，那加入后就是 worker，使用的 manager 的 token，加入后就是 manager 常用涉及 token 的命令如下 bash docker swarm join-token worker # 查看加入woker的命令 docker swarm join-token manager # 查看加入manager的命令 docker swarm join-token --rotate worker # 重置woker的Token docker swarm join-token -q worker # 仅打印Token\r","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:6:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#61-集群创建"},{"categories":["distributed system"],"content":"\r6.2 基于 Portainer 的可视化参考：可视化工具 Portainer Swarm 集群部署完成后可以通过各命令操作，当然也可以通过 Portainer 来进行 Swarm 集群的可视化管理 Portainer 是一款轻量级的开源应用，它提供了图形化界面，用于方便地管理 Docker 环境，包括单机环境和集群环境 如果部署了包含 Portainer 的Docker环境，可直接登录使用，否则，先安装 Portainer： bash docker volume create portainer_data # 首次创建 docker run -d -p 9000:9000 --name portainer -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer\r以上是使用独立容器启动 Portainer，也可以通过 Docker Compose 进行启动，docker-compose.yml 文件内容如下: yaml version: '3' volumes: portainer_data: services: portainer: image: portainer/portainer ports: - \"9000:9000\" command: -H unix:///var/run/docker.sock volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data\r文件编写完毕后通过 docker-compose up -d 命令可启动容器（可通过 -f 选项指定文件） 注：这里使用 docker run 或使用 docker-compose 方式启动的容器都是在一个节点上，不是 swarm 集群中运行，要让其在 swarm 集群中可使用 docker stack deploy命令 容器启动后，访问 https://192.168.56.101:9000 即可进入 webUI 界面，如图（192.168.56.101 为运行该容器所在节点的 ip） 注：首次进入需设置用户名与密码 在 portainer 页面可创建、删除容器、查看 swarm 信息等 查看 swarm 信息 进入容器 容器控制界面 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:6:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#62-基于-portainer-的可视化"},{"categories":["distributed system"],"content":"\r7. Swarm 集群使用","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#7-swarm-集群使用"},{"categories":["distributed system"],"content":"\r7.1 网络模式参考 docker swarm 网络模式 swarm： overlay： ingress：特殊的 Overlay 网络，具有负载均衡功能 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#71-网络模式"},{"categories":["distributed system"],"content":"\r7.2 Docker service 服务是一组运行于集群不同结点中可复制的容器的集合。通过服务发现机制，使用该服务的客户端可以透明的访问这些容器。这些容器的分布、升级、故障管理有集群统一管理。一般地，集群内部服务容器地选择由 动态DNS 实现 docker run：不具有扩缩容的功能 docker service：启动服务，具有扩缩容功能，滚动更新等功能 4.1.1 创建服务\rbash docker service create -p 8888:80 --name my-nginx nginx\r创建的服务从集群中任意主机 ip 都可访问 上述访问的是 slave01 的 ip，但容器运行在 master 节点上 4.1.2 查看服务（在 manager 节点上执行）\rbash docker service ls docker service inspect my-nginx # 查看该服务详细信息\rtxt (base) [hadoop@master composetest]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS vah2ryttads6 my-nginx replicated 1/1 nginx:latest *:8888-\u003e80/tcp\r可以看到在服务中有REPLICAS（副本）的概念，其代表这一服务有多少分副本 4.1.3 更新服务\rbash docker service update --replicas 3 my-nginx\r上述命令将 my-nginx 服务副本更新为 3，即集群中有 3 个运行nginx的容器，当选择的节点上没有该镜像时会自动下载；如指定 replicas 为 1 就能回到开始状态，达到动态缩容的效果 注：只要是一个服务，那么在集群中的任意一个节点都可以访问 除了上述的 update 方式，还可以使用 scale 命令扩缩容 bash docker service scale my-nginx=2\r4.1.4 删除服务命令\rbash docker service rm my-nginx\r命令 -\u003e 管理节点 -\u003e api -\u003e 调度 -\u003e 工作节点（创建容器，即Task任务） ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#72-docker-service"},{"categories":["distributed system"],"content":"\r7.2 Docker service 服务是一组运行于集群不同结点中可复制的容器的集合。通过服务发现机制，使用该服务的客户端可以透明的访问这些容器。这些容器的分布、升级、故障管理有集群统一管理。一般地，集群内部服务容器地选择由 动态DNS 实现 docker run：不具有扩缩容的功能 docker service：启动服务，具有扩缩容功能，滚动更新等功能 4.1.1 创建服务\rbash docker service create -p 8888:80 --name my-nginx nginx\r创建的服务从集群中任意主机 ip 都可访问 上述访问的是 slave01 的 ip，但容器运行在 master 节点上 4.1.2 查看服务（在 manager 节点上执行）\rbash docker service ls docker service inspect my-nginx # 查看该服务详细信息\rtxt (base) [hadoop@master composetest]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS vah2ryttads6 my-nginx replicated 1/1 nginx:latest *:8888-\u003e80/tcp\r可以看到在服务中有REPLICAS（副本）的概念，其代表这一服务有多少分副本 4.1.3 更新服务\rbash docker service update --replicas 3 my-nginx\r上述命令将 my-nginx 服务副本更新为 3，即集群中有 3 个运行nginx的容器，当选择的节点上没有该镜像时会自动下载；如指定 replicas 为 1 就能回到开始状态，达到动态缩容的效果 注：只要是一个服务，那么在集群中的任意一个节点都可以访问 除了上述的 update 方式，还可以使用 scale 命令扩缩容 bash docker service scale my-nginx=2\r4.1.4 删除服务命令\rbash docker service rm my-nginx\r命令 -\u003e 管理节点 -\u003e api -\u003e 调度 -\u003e 工作节点（创建容器，即Task任务） ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#411-创建服务"},{"categories":["distributed system"],"content":"\r7.2 Docker service 服务是一组运行于集群不同结点中可复制的容器的集合。通过服务发现机制，使用该服务的客户端可以透明的访问这些容器。这些容器的分布、升级、故障管理有集群统一管理。一般地，集群内部服务容器地选择由 动态DNS 实现 docker run：不具有扩缩容的功能 docker service：启动服务，具有扩缩容功能，滚动更新等功能 4.1.1 创建服务\rbash docker service create -p 8888:80 --name my-nginx nginx\r创建的服务从集群中任意主机 ip 都可访问 上述访问的是 slave01 的 ip，但容器运行在 master 节点上 4.1.2 查看服务（在 manager 节点上执行）\rbash docker service ls docker service inspect my-nginx # 查看该服务详细信息\rtxt (base) [hadoop@master composetest]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS vah2ryttads6 my-nginx replicated 1/1 nginx:latest *:8888-\u003e80/tcp\r可以看到在服务中有REPLICAS（副本）的概念，其代表这一服务有多少分副本 4.1.3 更新服务\rbash docker service update --replicas 3 my-nginx\r上述命令将 my-nginx 服务副本更新为 3，即集群中有 3 个运行nginx的容器，当选择的节点上没有该镜像时会自动下载；如指定 replicas 为 1 就能回到开始状态，达到动态缩容的效果 注：只要是一个服务，那么在集群中的任意一个节点都可以访问 除了上述的 update 方式，还可以使用 scale 命令扩缩容 bash docker service scale my-nginx=2\r4.1.4 删除服务命令\rbash docker service rm my-nginx\r命令 -\u003e 管理节点 -\u003e api -\u003e 调度 -\u003e 工作节点（创建容器，即Task任务） ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#412-查看服务在-manager-节点上执行"},{"categories":["distributed system"],"content":"\r7.2 Docker service 服务是一组运行于集群不同结点中可复制的容器的集合。通过服务发现机制，使用该服务的客户端可以透明的访问这些容器。这些容器的分布、升级、故障管理有集群统一管理。一般地，集群内部服务容器地选择由 动态DNS 实现 docker run：不具有扩缩容的功能 docker service：启动服务，具有扩缩容功能，滚动更新等功能 4.1.1 创建服务\rbash docker service create -p 8888:80 --name my-nginx nginx\r创建的服务从集群中任意主机 ip 都可访问 上述访问的是 slave01 的 ip，但容器运行在 master 节点上 4.1.2 查看服务（在 manager 节点上执行）\rbash docker service ls docker service inspect my-nginx # 查看该服务详细信息\rtxt (base) [hadoop@master composetest]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS vah2ryttads6 my-nginx replicated 1/1 nginx:latest *:8888-\u003e80/tcp\r可以看到在服务中有REPLICAS（副本）的概念，其代表这一服务有多少分副本 4.1.3 更新服务\rbash docker service update --replicas 3 my-nginx\r上述命令将 my-nginx 服务副本更新为 3，即集群中有 3 个运行nginx的容器，当选择的节点上没有该镜像时会自动下载；如指定 replicas 为 1 就能回到开始状态，达到动态缩容的效果 注：只要是一个服务，那么在集群中的任意一个节点都可以访问 除了上述的 update 方式，还可以使用 scale 命令扩缩容 bash docker service scale my-nginx=2\r4.1.4 删除服务命令\rbash docker service rm my-nginx\r命令 -\u003e 管理节点 -\u003e api -\u003e 调度 -\u003e 工作节点（创建容器，即Task任务） ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#413-更新服务"},{"categories":["distributed system"],"content":"\r7.2 Docker service 服务是一组运行于集群不同结点中可复制的容器的集合。通过服务发现机制，使用该服务的客户端可以透明的访问这些容器。这些容器的分布、升级、故障管理有集群统一管理。一般地，集群内部服务容器地选择由 动态DNS 实现 docker run：不具有扩缩容的功能 docker service：启动服务，具有扩缩容功能，滚动更新等功能 4.1.1 创建服务\rbash docker service create -p 8888:80 --name my-nginx nginx\r创建的服务从集群中任意主机 ip 都可访问 上述访问的是 slave01 的 ip，但容器运行在 master 节点上 4.1.2 查看服务（在 manager 节点上执行）\rbash docker service ls docker service inspect my-nginx # 查看该服务详细信息\rtxt (base) [hadoop@master composetest]$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS vah2ryttads6 my-nginx replicated 1/1 nginx:latest *:8888-\u003e80/tcp\r可以看到在服务中有REPLICAS（副本）的概念，其代表这一服务有多少分副本 4.1.3 更新服务\rbash docker service update --replicas 3 my-nginx\r上述命令将 my-nginx 服务副本更新为 3，即集群中有 3 个运行nginx的容器，当选择的节点上没有该镜像时会自动下载；如指定 replicas 为 1 就能回到开始状态，达到动态缩容的效果 注：只要是一个服务，那么在集群中的任意一个节点都可以访问 除了上述的 update 方式，还可以使用 scale 命令扩缩容 bash docker service scale my-nginx=2\r4.1.4 删除服务命令\rbash docker service rm my-nginx\r命令 -\u003e 管理节点 -\u003e api -\u003e 调度 -\u003e 工作节点（创建容器，即Task任务） ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#414-删除服务命令"},{"categories":["distributed system"],"content":"\r7.3 Docker stack参考:https://yeasy.gitbook.io/docker_practice/swarm_mode/stack docker-compose:单机部署 docker stack：集群上部署 使用 docker-compose.yml 来一次配置、启动多个容器，在 Swarm 集群中也可以使用 compose 文件 （docker-compose.yml） 来配置、启动多个服务。 docker service create 一次只能部署一个服务，使用 docker-compose.yml 我们可以一次启动多个关联的服务。 命令如下，其中 -c 指定 compose 文件名 bash docker stack deploy -c docker-compose.yml wordpress\rbash docker service create --mount type=volume,src=volume,dst=/data --name uchin_v_test busybox ping\rDocker Swarm（四）Volume 数据（挂载）持久化 创建数据卷 创建 overlay bash docker network create kafka --driver overlay --subnet 172.30.0.0/16 --gateway 172.30.0.1 docker network create kafka --driver overlay --attachable --subnet 172.30.0.0/16 --gateway 172.30.0.1\r创建数据卷 参考：https://blog.csdn.net/even160941/article/details/99324273 bash docker volume create --name volume_kafka\rbash docker service create --name uchin_test --network kafka --mount type=volume,src=volume_kafka,dst=/home --replicas 2 centos\rbash docker service create --network kafka -p 8888:80 --name my-nginx --mount type=volume,src=volume_kafka,dst=/home nginx\rdocker swarm 模式下，如何固定容器的ip？ docker run -it –network kafka -v /home/hadoop/workspace/zkk/zk_volumes/app/:/home –name myCL python /bin/bash docker run -it –network kafka -v /home/hadoop/workspace/zkk/zk_volumes/app/:/home –name myConsumer continuumio/anaconda3 /bin/bash ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:7:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#73-docker-stack"},{"categories":["distributed system"],"content":"\r8. Swarm 工作原理","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#8-swarm-工作原理httpsholynullgitbooksiodocker-swarmcontentswarmmo-shi-gong-zuo-yuan-lihtml"},{"categories":["distributed system"],"content":"\r8.1 节点工作原理参考：swarm 节点工作原理 Swarm 集群中的节点分为两类：managers 和 workers，集群中可有多个 manager 和 worker。Manager 通过 Raft 协议来使 Swarm 的整体维持在一个一致的内部状态上，service 则运行在这个一致的内部状态之上。 8.1.1 Manager 节点Manager 节点用来处理集群管理任务： 维护集群状态 调度 service 提供 swarm 模式 HTTP API 端点 推荐使 Swarm 的节点为奇数个，来实现高可用的要求。当采用多个 manager 节点时，我们就可以在不停止集群运行的情况下恢复停止运行的manager节点。 3个manager节点最大容错允许1个manager不可用 5个manager节点最大容错允许2个manager不可用。 N个manager节点最大容错允许(N-1)/2个manager节点不可用。 建议最大 manager 节点数为7个。 8.1.2 Worker 节点Worker节点也是 Docker Engine 的实例，目的是用来运行 Container。Worker 节点不会像 Manager 节点那样提供集群的管理、任务调度和API。 可以创建仅有一个manager节点的Swarm，但是不能在没有manager节点的前提下，创建Worker节点。在默认情况下，manager 节点同时也是一个 worker 节点。 在一个manager节点的集群中，执行``docker service create`命令，调度器会将所有的task调度在本地Docker Engine上执行。 要阻止调度器将task分配到 manager 节点上执行，就需要将 manager 节点的可用性状态设置成 DRAIN。调度器会停止 DRAIN 节点上的 task，转移到其他状态为 ACTIVE 的节点上继续运行停止的 task。并且调度器不会再将新的 task 分配给 DRAIN 状态的节点。 8.1.3 改变节点角色我们可以通过``docker node promote`来将一个 worker 节点修改成一个 manager 节点。例如，某些维护需要，我们将停止一个 manager 节点，这时我们可以将某一个正在运行的worker节点变成manager节点，来代替停止的那个manager节点。当然，同样也可将一个manager节点改成一个worker节点。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#81-节点工作原理"},{"categories":["distributed system"],"content":"\r8.1 节点工作原理参考：swarm 节点工作原理 Swarm 集群中的节点分为两类：managers 和 workers，集群中可有多个 manager 和 worker。Manager 通过 Raft 协议来使 Swarm 的整体维持在一个一致的内部状态上，service 则运行在这个一致的内部状态之上。 8.1.1 Manager 节点Manager 节点用来处理集群管理任务： 维护集群状态 调度 service 提供 swarm 模式 HTTP API 端点 推荐使 Swarm 的节点为奇数个，来实现高可用的要求。当采用多个 manager 节点时，我们就可以在不停止集群运行的情况下恢复停止运行的manager节点。 3个manager节点最大容错允许1个manager不可用 5个manager节点最大容错允许2个manager不可用。 N个manager节点最大容错允许(N-1)/2个manager节点不可用。 建议最大 manager 节点数为7个。 8.1.2 Worker 节点Worker节点也是 Docker Engine 的实例，目的是用来运行 Container。Worker 节点不会像 Manager 节点那样提供集群的管理、任务调度和API。 可以创建仅有一个manager节点的Swarm，但是不能在没有manager节点的前提下，创建Worker节点。在默认情况下，manager 节点同时也是一个 worker 节点。 在一个manager节点的集群中，执行``docker service create`命令，调度器会将所有的task调度在本地Docker Engine上执行。 要阻止调度器将task分配到 manager 节点上执行，就需要将 manager 节点的可用性状态设置成 DRAIN。调度器会停止 DRAIN 节点上的 task，转移到其他状态为 ACTIVE 的节点上继续运行停止的 task。并且调度器不会再将新的 task 分配给 DRAIN 状态的节点。 8.1.3 改变节点角色我们可以通过``docker node promote`来将一个 worker 节点修改成一个 manager 节点。例如，某些维护需要，我们将停止一个 manager 节点，这时我们可以将某一个正在运行的worker节点变成manager节点，来代替停止的那个manager节点。当然，同样也可将一个manager节点改成一个worker节点。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#811-manager-节点"},{"categories":["distributed system"],"content":"\r8.1 节点工作原理参考：swarm 节点工作原理 Swarm 集群中的节点分为两类：managers 和 workers，集群中可有多个 manager 和 worker。Manager 通过 Raft 协议来使 Swarm 的整体维持在一个一致的内部状态上，service 则运行在这个一致的内部状态之上。 8.1.1 Manager 节点Manager 节点用来处理集群管理任务： 维护集群状态 调度 service 提供 swarm 模式 HTTP API 端点 推荐使 Swarm 的节点为奇数个，来实现高可用的要求。当采用多个 manager 节点时，我们就可以在不停止集群运行的情况下恢复停止运行的manager节点。 3个manager节点最大容错允许1个manager不可用 5个manager节点最大容错允许2个manager不可用。 N个manager节点最大容错允许(N-1)/2个manager节点不可用。 建议最大 manager 节点数为7个。 8.1.2 Worker 节点Worker节点也是 Docker Engine 的实例，目的是用来运行 Container。Worker 节点不会像 Manager 节点那样提供集群的管理、任务调度和API。 可以创建仅有一个manager节点的Swarm，但是不能在没有manager节点的前提下，创建Worker节点。在默认情况下，manager 节点同时也是一个 worker 节点。 在一个manager节点的集群中，执行``docker service create`命令，调度器会将所有的task调度在本地Docker Engine上执行。 要阻止调度器将task分配到 manager 节点上执行，就需要将 manager 节点的可用性状态设置成 DRAIN。调度器会停止 DRAIN 节点上的 task，转移到其他状态为 ACTIVE 的节点上继续运行停止的 task。并且调度器不会再将新的 task 分配给 DRAIN 状态的节点。 8.1.3 改变节点角色我们可以通过``docker node promote`来将一个 worker 节点修改成一个 manager 节点。例如，某些维护需要，我们将停止一个 manager 节点，这时我们可以将某一个正在运行的worker节点变成manager节点，来代替停止的那个manager节点。当然，同样也可将一个manager节点改成一个worker节点。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#812-worker-节点"},{"categories":["distributed system"],"content":"\r8.1 节点工作原理参考：swarm 节点工作原理 Swarm 集群中的节点分为两类：managers 和 workers，集群中可有多个 manager 和 worker。Manager 通过 Raft 协议来使 Swarm 的整体维持在一个一致的内部状态上，service 则运行在这个一致的内部状态之上。 8.1.1 Manager 节点Manager 节点用来处理集群管理任务： 维护集群状态 调度 service 提供 swarm 模式 HTTP API 端点 推荐使 Swarm 的节点为奇数个，来实现高可用的要求。当采用多个 manager 节点时，我们就可以在不停止集群运行的情况下恢复停止运行的manager节点。 3个manager节点最大容错允许1个manager不可用 5个manager节点最大容错允许2个manager不可用。 N个manager节点最大容错允许(N-1)/2个manager节点不可用。 建议最大 manager 节点数为7个。 8.1.2 Worker 节点Worker节点也是 Docker Engine 的实例，目的是用来运行 Container。Worker 节点不会像 Manager 节点那样提供集群的管理、任务调度和API。 可以创建仅有一个manager节点的Swarm，但是不能在没有manager节点的前提下，创建Worker节点。在默认情况下，manager 节点同时也是一个 worker 节点。 在一个manager节点的集群中，执行``docker service create`命令，调度器会将所有的task调度在本地Docker Engine上执行。 要阻止调度器将task分配到 manager 节点上执行，就需要将 manager 节点的可用性状态设置成 DRAIN。调度器会停止 DRAIN 节点上的 task，转移到其他状态为 ACTIVE 的节点上继续运行停止的 task。并且调度器不会再将新的 task 分配给 DRAIN 状态的节点。 8.1.3 改变节点角色我们可以通过``docker node promote`来将一个 worker 节点修改成一个 manager 节点。例如，某些维护需要，我们将停止一个 manager 节点，这时我们可以将某一个正在运行的worker节点变成manager节点，来代替停止的那个manager节点。当然，同样也可将一个manager节点改成一个worker节点。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:1","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#813-改变节点角色"},{"categories":["distributed system"],"content":"\r8.2 Service 工作原理参考Service工作原理 为了部署一个应用的镜像到 Swarm 模式的 Docker Engine 中，我们需要创建一个 service。通常 service 是拥有大型应用系统上下文信息的微服务镜像。例如，一个服务可能包含一个HTTP服务器、一个数据库、或者其他的软件，我们需要这些软件运行在一个分布式环境中。 当创建 service 时，我们需要指定用什么镜像运行 container，以及 container 内部运行什么样的命令。我们还需要定义以下内容： service 向 Swarm 以外暴露的可用端口 一个 overlay network，用来支持 service 之间相互通信 CPU和内存的限制和预设 滚动更新的策略 镜像在Swarm中运行的副本数 8.2.1 Service，Tasks and Containers当我们部署一个 service 到 swarm 时，manager 节点将接受我们对 service 定义，并作为 service 的理想状态。Manager 节点在 swarm 节点之间调度 service 的副本。不同节点上运行的 task 是相互独立的。 例如，我们设想在3个HTTP监听实例之间实现负载均衡。下图展示了拥有3个副本的HTTP监听器。每一个监听器实例就是一个 swarm 中的 task。 一个 container 是一个被隔离的进程。在 swarm 模式的模型中，每一个 task 运行一个 container。task 就像调度器放置 container 使用的一个“槽”。一旦 container 运行起来，调度器就能意识到task是在运行状态。如果 container 不可用或者被终止，则 task 也将被终止。 8.2.2 task和调度task 是 swarm 调度的原子单元。当创建和更新 service 时，我们声明了 service 的理想状态，协调器通过调度 task 来实现这个理想状态。例如，我们定义了一个service，要求协调器在任何时候都能保证有3个HTTP监听器在运行。协调器创建3个task作为回应。每一个task就像一个“槽”，调度器将产生3个 container 放在“槽”中。container 是 task 的一个实例。当一个HTTP监听器不可用或者崩溃，协调器将创建一个新的task副本，并放入一个新的container。 task 的状态变化采用一种单向机制。贯穿 task 生命周期的状态有：已分配状态、已准备状态、正在运行状态，等等。如果task运行失败了，协调器会移除这个 task 并停止它的 container，然后创建新的 task 替代它，以保证service定义的理想状态。 Swarm模式背后的逻辑其实是一种通用的调度器和协调器逻辑。service和task被抽象设计成并不需要知道他们实现的container是什么样的。假设，我们可以实现其他类型的task，例如虚拟机task或者非容器化的进程task。调度器和协调器并不需要知道task的类型。然而，当前版本的Docker只支持容器task。 下图展示了Swarm模式如何接收service的创建请求，并调度task到worker节点。 8.2.3 Pending services由于配置的原因，某些 service 在当前swarm中没有节点可以执行它的task。在这种情况下，service 会一直保持 pending 状态。下面的一些例子会造成service保持pending状态。 注意：如果有意要阻止 service 被发布，应该将 service 的 scale 设置为0，而不是通过设置让 service 一直保持在 pending 状态上。 如果所有的节点都暂停了或者都处于DRAIN状态，创建service时就会一直处于pending状态，知道有节点变为可用状态。事实上，当一个节点可用时，所有的任务都会被分配到这个节点上，所以对于生产环境来说并不是一件好事。 可以事先给service划定一定的内存。如果没有一个节点具有所需要的内存空间量，service会一直保持pending状态，直到一个节点变的可用。 可以强制service的放置约束，短时间内可能达不到约束条件。 以上说明需求和task的配置没有紧密的结合到swarm的当前状态。作为Swarm的管理员，生命Swarm的理想状态，manager节点结合其他节点在Swarm中创建出这个状态。就不需要将管理的粒度细化到task级别。 8.2.4 复制和全局service有两种service的部署模式，复制和全局。 设置task的数量来实现复制模式下的service。例如，想要部署3个副本的HTTP服务，每个副本都提供相同的服务。 全局service是在所有节点上都有一个task的service。不能指定task的数量。每次增加一个节点，协调器会创建一个task，并有调度器分配到新节点上。全局service的最佳应用是部署监控代理，病毒扫描，以及其他希望在swarm中每个节点上都部署的service。 下图展示了3个副本的service和一个全局service部署在swarm中的情况，黄色代表3个副本的service，灰色代表全局service： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#82-service-工作原理"},{"categories":["distributed system"],"content":"\r8.2 Service 工作原理参考Service工作原理 为了部署一个应用的镜像到 Swarm 模式的 Docker Engine 中，我们需要创建一个 service。通常 service 是拥有大型应用系统上下文信息的微服务镜像。例如，一个服务可能包含一个HTTP服务器、一个数据库、或者其他的软件，我们需要这些软件运行在一个分布式环境中。 当创建 service 时，我们需要指定用什么镜像运行 container，以及 container 内部运行什么样的命令。我们还需要定义以下内容： service 向 Swarm 以外暴露的可用端口 一个 overlay network，用来支持 service 之间相互通信 CPU和内存的限制和预设 滚动更新的策略 镜像在Swarm中运行的副本数 8.2.1 Service，Tasks and Containers当我们部署一个 service 到 swarm 时，manager 节点将接受我们对 service 定义，并作为 service 的理想状态。Manager 节点在 swarm 节点之间调度 service 的副本。不同节点上运行的 task 是相互独立的。 例如，我们设想在3个HTTP监听实例之间实现负载均衡。下图展示了拥有3个副本的HTTP监听器。每一个监听器实例就是一个 swarm 中的 task。 一个 container 是一个被隔离的进程。在 swarm 模式的模型中，每一个 task 运行一个 container。task 就像调度器放置 container 使用的一个“槽”。一旦 container 运行起来，调度器就能意识到task是在运行状态。如果 container 不可用或者被终止，则 task 也将被终止。 8.2.2 task和调度task 是 swarm 调度的原子单元。当创建和更新 service 时，我们声明了 service 的理想状态，协调器通过调度 task 来实现这个理想状态。例如，我们定义了一个service，要求协调器在任何时候都能保证有3个HTTP监听器在运行。协调器创建3个task作为回应。每一个task就像一个“槽”，调度器将产生3个 container 放在“槽”中。container 是 task 的一个实例。当一个HTTP监听器不可用或者崩溃，协调器将创建一个新的task副本，并放入一个新的container。 task 的状态变化采用一种单向机制。贯穿 task 生命周期的状态有：已分配状态、已准备状态、正在运行状态，等等。如果task运行失败了，协调器会移除这个 task 并停止它的 container，然后创建新的 task 替代它，以保证service定义的理想状态。 Swarm模式背后的逻辑其实是一种通用的调度器和协调器逻辑。service和task被抽象设计成并不需要知道他们实现的container是什么样的。假设，我们可以实现其他类型的task，例如虚拟机task或者非容器化的进程task。调度器和协调器并不需要知道task的类型。然而，当前版本的Docker只支持容器task。 下图展示了Swarm模式如何接收service的创建请求，并调度task到worker节点。 8.2.3 Pending services由于配置的原因，某些 service 在当前swarm中没有节点可以执行它的task。在这种情况下，service 会一直保持 pending 状态。下面的一些例子会造成service保持pending状态。 注意：如果有意要阻止 service 被发布，应该将 service 的 scale 设置为0，而不是通过设置让 service 一直保持在 pending 状态上。 如果所有的节点都暂停了或者都处于DRAIN状态，创建service时就会一直处于pending状态，知道有节点变为可用状态。事实上，当一个节点可用时，所有的任务都会被分配到这个节点上，所以对于生产环境来说并不是一件好事。 可以事先给service划定一定的内存。如果没有一个节点具有所需要的内存空间量，service会一直保持pending状态，直到一个节点变的可用。 可以强制service的放置约束，短时间内可能达不到约束条件。 以上说明需求和task的配置没有紧密的结合到swarm的当前状态。作为Swarm的管理员，生命Swarm的理想状态，manager节点结合其他节点在Swarm中创建出这个状态。就不需要将管理的粒度细化到task级别。 8.2.4 复制和全局service有两种service的部署模式，复制和全局。 设置task的数量来实现复制模式下的service。例如，想要部署3个副本的HTTP服务，每个副本都提供相同的服务。 全局service是在所有节点上都有一个task的service。不能指定task的数量。每次增加一个节点，协调器会创建一个task，并有调度器分配到新节点上。全局service的最佳应用是部署监控代理，病毒扫描，以及其他希望在swarm中每个节点上都部署的service。 下图展示了3个副本的service和一个全局service部署在swarm中的情况，黄色代表3个副本的service，灰色代表全局service： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#821-servicetasks-and-containers"},{"categories":["distributed system"],"content":"\r8.2 Service 工作原理参考Service工作原理 为了部署一个应用的镜像到 Swarm 模式的 Docker Engine 中，我们需要创建一个 service。通常 service 是拥有大型应用系统上下文信息的微服务镜像。例如，一个服务可能包含一个HTTP服务器、一个数据库、或者其他的软件，我们需要这些软件运行在一个分布式环境中。 当创建 service 时，我们需要指定用什么镜像运行 container，以及 container 内部运行什么样的命令。我们还需要定义以下内容： service 向 Swarm 以外暴露的可用端口 一个 overlay network，用来支持 service 之间相互通信 CPU和内存的限制和预设 滚动更新的策略 镜像在Swarm中运行的副本数 8.2.1 Service，Tasks and Containers当我们部署一个 service 到 swarm 时，manager 节点将接受我们对 service 定义，并作为 service 的理想状态。Manager 节点在 swarm 节点之间调度 service 的副本。不同节点上运行的 task 是相互独立的。 例如，我们设想在3个HTTP监听实例之间实现负载均衡。下图展示了拥有3个副本的HTTP监听器。每一个监听器实例就是一个 swarm 中的 task。 一个 container 是一个被隔离的进程。在 swarm 模式的模型中，每一个 task 运行一个 container。task 就像调度器放置 container 使用的一个“槽”。一旦 container 运行起来，调度器就能意识到task是在运行状态。如果 container 不可用或者被终止，则 task 也将被终止。 8.2.2 task和调度task 是 swarm 调度的原子单元。当创建和更新 service 时，我们声明了 service 的理想状态，协调器通过调度 task 来实现这个理想状态。例如，我们定义了一个service，要求协调器在任何时候都能保证有3个HTTP监听器在运行。协调器创建3个task作为回应。每一个task就像一个“槽”，调度器将产生3个 container 放在“槽”中。container 是 task 的一个实例。当一个HTTP监听器不可用或者崩溃，协调器将创建一个新的task副本，并放入一个新的container。 task 的状态变化采用一种单向机制。贯穿 task 生命周期的状态有：已分配状态、已准备状态、正在运行状态，等等。如果task运行失败了，协调器会移除这个 task 并停止它的 container，然后创建新的 task 替代它，以保证service定义的理想状态。 Swarm模式背后的逻辑其实是一种通用的调度器和协调器逻辑。service和task被抽象设计成并不需要知道他们实现的container是什么样的。假设，我们可以实现其他类型的task，例如虚拟机task或者非容器化的进程task。调度器和协调器并不需要知道task的类型。然而，当前版本的Docker只支持容器task。 下图展示了Swarm模式如何接收service的创建请求，并调度task到worker节点。 8.2.3 Pending services由于配置的原因，某些 service 在当前swarm中没有节点可以执行它的task。在这种情况下，service 会一直保持 pending 状态。下面的一些例子会造成service保持pending状态。 注意：如果有意要阻止 service 被发布，应该将 service 的 scale 设置为0，而不是通过设置让 service 一直保持在 pending 状态上。 如果所有的节点都暂停了或者都处于DRAIN状态，创建service时就会一直处于pending状态，知道有节点变为可用状态。事实上，当一个节点可用时，所有的任务都会被分配到这个节点上，所以对于生产环境来说并不是一件好事。 可以事先给service划定一定的内存。如果没有一个节点具有所需要的内存空间量，service会一直保持pending状态，直到一个节点变的可用。 可以强制service的放置约束，短时间内可能达不到约束条件。 以上说明需求和task的配置没有紧密的结合到swarm的当前状态。作为Swarm的管理员，生命Swarm的理想状态，manager节点结合其他节点在Swarm中创建出这个状态。就不需要将管理的粒度细化到task级别。 8.2.4 复制和全局service有两种service的部署模式，复制和全局。 设置task的数量来实现复制模式下的service。例如，想要部署3个副本的HTTP服务，每个副本都提供相同的服务。 全局service是在所有节点上都有一个task的service。不能指定task的数量。每次增加一个节点，协调器会创建一个task，并有调度器分配到新节点上。全局service的最佳应用是部署监控代理，病毒扫描，以及其他希望在swarm中每个节点上都部署的service。 下图展示了3个副本的service和一个全局service部署在swarm中的情况，黄色代表3个副本的service，灰色代表全局service： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#822-task和调度"},{"categories":["distributed system"],"content":"\r8.2 Service 工作原理参考Service工作原理 为了部署一个应用的镜像到 Swarm 模式的 Docker Engine 中，我们需要创建一个 service。通常 service 是拥有大型应用系统上下文信息的微服务镜像。例如，一个服务可能包含一个HTTP服务器、一个数据库、或者其他的软件，我们需要这些软件运行在一个分布式环境中。 当创建 service 时，我们需要指定用什么镜像运行 container，以及 container 内部运行什么样的命令。我们还需要定义以下内容： service 向 Swarm 以外暴露的可用端口 一个 overlay network，用来支持 service 之间相互通信 CPU和内存的限制和预设 滚动更新的策略 镜像在Swarm中运行的副本数 8.2.1 Service，Tasks and Containers当我们部署一个 service 到 swarm 时，manager 节点将接受我们对 service 定义，并作为 service 的理想状态。Manager 节点在 swarm 节点之间调度 service 的副本。不同节点上运行的 task 是相互独立的。 例如，我们设想在3个HTTP监听实例之间实现负载均衡。下图展示了拥有3个副本的HTTP监听器。每一个监听器实例就是一个 swarm 中的 task。 一个 container 是一个被隔离的进程。在 swarm 模式的模型中，每一个 task 运行一个 container。task 就像调度器放置 container 使用的一个“槽”。一旦 container 运行起来，调度器就能意识到task是在运行状态。如果 container 不可用或者被终止，则 task 也将被终止。 8.2.2 task和调度task 是 swarm 调度的原子单元。当创建和更新 service 时，我们声明了 service 的理想状态，协调器通过调度 task 来实现这个理想状态。例如，我们定义了一个service，要求协调器在任何时候都能保证有3个HTTP监听器在运行。协调器创建3个task作为回应。每一个task就像一个“槽”，调度器将产生3个 container 放在“槽”中。container 是 task 的一个实例。当一个HTTP监听器不可用或者崩溃，协调器将创建一个新的task副本，并放入一个新的container。 task 的状态变化采用一种单向机制。贯穿 task 生命周期的状态有：已分配状态、已准备状态、正在运行状态，等等。如果task运行失败了，协调器会移除这个 task 并停止它的 container，然后创建新的 task 替代它，以保证service定义的理想状态。 Swarm模式背后的逻辑其实是一种通用的调度器和协调器逻辑。service和task被抽象设计成并不需要知道他们实现的container是什么样的。假设，我们可以实现其他类型的task，例如虚拟机task或者非容器化的进程task。调度器和协调器并不需要知道task的类型。然而，当前版本的Docker只支持容器task。 下图展示了Swarm模式如何接收service的创建请求，并调度task到worker节点。 8.2.3 Pending services由于配置的原因，某些 service 在当前swarm中没有节点可以执行它的task。在这种情况下，service 会一直保持 pending 状态。下面的一些例子会造成service保持pending状态。 注意：如果有意要阻止 service 被发布，应该将 service 的 scale 设置为0，而不是通过设置让 service 一直保持在 pending 状态上。 如果所有的节点都暂停了或者都处于DRAIN状态，创建service时就会一直处于pending状态，知道有节点变为可用状态。事实上，当一个节点可用时，所有的任务都会被分配到这个节点上，所以对于生产环境来说并不是一件好事。 可以事先给service划定一定的内存。如果没有一个节点具有所需要的内存空间量，service会一直保持pending状态，直到一个节点变的可用。 可以强制service的放置约束，短时间内可能达不到约束条件。 以上说明需求和task的配置没有紧密的结合到swarm的当前状态。作为Swarm的管理员，生命Swarm的理想状态，manager节点结合其他节点在Swarm中创建出这个状态。就不需要将管理的粒度细化到task级别。 8.2.4 复制和全局service有两种service的部署模式，复制和全局。 设置task的数量来实现复制模式下的service。例如，想要部署3个副本的HTTP服务，每个副本都提供相同的服务。 全局service是在所有节点上都有一个task的service。不能指定task的数量。每次增加一个节点，协调器会创建一个task，并有调度器分配到新节点上。全局service的最佳应用是部署监控代理，病毒扫描，以及其他希望在swarm中每个节点上都部署的service。 下图展示了3个副本的service和一个全局service部署在swarm中的情况，黄色代表3个副本的service，灰色代表全局service： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#823-pending-services"},{"categories":["distributed system"],"content":"\r8.2 Service 工作原理参考Service工作原理 为了部署一个应用的镜像到 Swarm 模式的 Docker Engine 中，我们需要创建一个 service。通常 service 是拥有大型应用系统上下文信息的微服务镜像。例如，一个服务可能包含一个HTTP服务器、一个数据库、或者其他的软件，我们需要这些软件运行在一个分布式环境中。 当创建 service 时，我们需要指定用什么镜像运行 container，以及 container 内部运行什么样的命令。我们还需要定义以下内容： service 向 Swarm 以外暴露的可用端口 一个 overlay network，用来支持 service 之间相互通信 CPU和内存的限制和预设 滚动更新的策略 镜像在Swarm中运行的副本数 8.2.1 Service，Tasks and Containers当我们部署一个 service 到 swarm 时，manager 节点将接受我们对 service 定义，并作为 service 的理想状态。Manager 节点在 swarm 节点之间调度 service 的副本。不同节点上运行的 task 是相互独立的。 例如，我们设想在3个HTTP监听实例之间实现负载均衡。下图展示了拥有3个副本的HTTP监听器。每一个监听器实例就是一个 swarm 中的 task。 一个 container 是一个被隔离的进程。在 swarm 模式的模型中，每一个 task 运行一个 container。task 就像调度器放置 container 使用的一个“槽”。一旦 container 运行起来，调度器就能意识到task是在运行状态。如果 container 不可用或者被终止，则 task 也将被终止。 8.2.2 task和调度task 是 swarm 调度的原子单元。当创建和更新 service 时，我们声明了 service 的理想状态，协调器通过调度 task 来实现这个理想状态。例如，我们定义了一个service，要求协调器在任何时候都能保证有3个HTTP监听器在运行。协调器创建3个task作为回应。每一个task就像一个“槽”，调度器将产生3个 container 放在“槽”中。container 是 task 的一个实例。当一个HTTP监听器不可用或者崩溃，协调器将创建一个新的task副本，并放入一个新的container。 task 的状态变化采用一种单向机制。贯穿 task 生命周期的状态有：已分配状态、已准备状态、正在运行状态，等等。如果task运行失败了，协调器会移除这个 task 并停止它的 container，然后创建新的 task 替代它，以保证service定义的理想状态。 Swarm模式背后的逻辑其实是一种通用的调度器和协调器逻辑。service和task被抽象设计成并不需要知道他们实现的container是什么样的。假设，我们可以实现其他类型的task，例如虚拟机task或者非容器化的进程task。调度器和协调器并不需要知道task的类型。然而，当前版本的Docker只支持容器task。 下图展示了Swarm模式如何接收service的创建请求，并调度task到worker节点。 8.2.3 Pending services由于配置的原因，某些 service 在当前swarm中没有节点可以执行它的task。在这种情况下，service 会一直保持 pending 状态。下面的一些例子会造成service保持pending状态。 注意：如果有意要阻止 service 被发布，应该将 service 的 scale 设置为0，而不是通过设置让 service 一直保持在 pending 状态上。 如果所有的节点都暂停了或者都处于DRAIN状态，创建service时就会一直处于pending状态，知道有节点变为可用状态。事实上，当一个节点可用时，所有的任务都会被分配到这个节点上，所以对于生产环境来说并不是一件好事。 可以事先给service划定一定的内存。如果没有一个节点具有所需要的内存空间量，service会一直保持pending状态，直到一个节点变的可用。 可以强制service的放置约束，短时间内可能达不到约束条件。 以上说明需求和task的配置没有紧密的结合到swarm的当前状态。作为Swarm的管理员，生命Swarm的理想状态，manager节点结合其他节点在Swarm中创建出这个状态。就不需要将管理的粒度细化到task级别。 8.2.4 复制和全局service有两种service的部署模式，复制和全局。 设置task的数量来实现复制模式下的service。例如，想要部署3个副本的HTTP服务，每个副本都提供相同的服务。 全局service是在所有节点上都有一个task的service。不能指定task的数量。每次增加一个节点，协调器会创建一个task，并有调度器分配到新节点上。全局service的最佳应用是部署监控代理，病毒扫描，以及其他希望在swarm中每个节点上都部署的service。 下图展示了3个副本的service和一个全局service部署在swarm中的情况，黄色代表3个副本的service，灰色代表全局service： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:2","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#824-复制和全局service"},{"categories":["distributed system"],"content":"\r8.3 安全(PKI)参考：安全 Docker内置了PKI，使保障发布容器化的业务流程系统的安全性变得很简单。Swarm节点之间采用TLS来鉴权、授权和加密通信。 当我们运行docker swarm init命令时，Docker指定当前节点为一个 manager 节点。默认情况下，manager 节点会生成一个新的根CA证书以及一对密钥。CA证书和密钥将会被用在节点之间的通信上。也可以通过参数–external-ca来指定其他CA证书。 Manager节点会生成两个token，一个用来添加worker节点，一个用来添加manager节点。每一个token包含了CA证书的digest和一个随机密钥。当节点加入到Swarm中时，加入的节点将digest发送给远端的manager节点，由manager节点来验证申请加入节点的根CA证书是否合法。远端manager节点通过随机密钥来验证申请加入的节点是否被核准加入。 每当节点加入到Swarm中后，manager都会给节点发送一个证书。这个证书中包含了一个随机生成的节点ID，用来标识这个证书通用名称下的节点，以及组织单元下的角色。在节点的当前Swarm生命周期中，节点ID是节点的安全加密的身份标识。 下图说明了manager节点和worker节点如何使用TSL 1.2进行通信加密的。 下面的例子展示了一个worker节点获得证书内容： bash Certificate: Data: Version: 3 (0x2) Serial Number: 3b:1c:06:91:73:fb:16:ff:69:c3:f7:a2:fe:96:c1:73:e2:80:97:3b Signature Algorithm: ecdsa-with-SHA256 Issuer: CN=swarm-ca Validity Not Before: Aug 30 02:39:00 2016 GMT Not After : Nov 28 03:39:00 2016 GMT Subject: O=ec2adilxf4ngv7ev8fwsi61i7, OU=swarm-worker, CN=dw02poa4vqvzxi5c10gm4pq2g ...snip...\r默认情况下，每个节点的证书3个月轮换一次。我们可以通过配置修改的这个间隔：docker swarm update –cert-expiry \u003cTIME PERIOD\u003e。最小的证书轮换时间为1小时。 8.3.1 CA证书轮换如果Swarm的CA密钥或Manager节点受到危害，您可以轮换Swarm的根CA证书，以使所有节点都不再信任旧的根CA签名的证书。 运行命令docker swarm ca --ratate来生成新的CA证书和密钥。也可以通过参数--ca-cert和--external-ca来指定外部的根CA证书。 当运行了docker swarm ca --rotate命令后，会按顺序发生下面的事情： Docker会生成一个交叉签名（cross-signed）证书。即新证书是由旧的证书签署的。这个交叉签名证书将作为一个过渡性的证书。这是为了确保节点仍然能够信任旧的证书，也能使用新的CA证书验证签名。 在Docker 17.06或者更高版本中，Docker会通知所有节点立即更新TLS证书。根据Swarm中节点的数量多少，这个过程可能会花费几分钟时间。 注意：如果Swarm中的节点上Docker的版本不一致，将会发生下面的情况： 只有manager节点运行了Docker 17.06或者更高版本，并且作为leader时，才能通知到其他节点更新TLS证书。 只有Docker 17.06或者更高版本才会支持这个指令。 最好确保所有的Swarm节点上运行Docker 17.06或者更高版本。 在所有的节点都更新了新CA证书签署的TLS证书后，Docker将不在信任旧的证书，并通知所有节点仅信任新的CA证书。 加入Swarm使用的token将发生变化，旧的token将不可用。 从这时起，所有新的由新根CA证书签署的节点证书将颁发给节点，并且完全不存在过度内容。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#83-安全pki"},{"categories":["distributed system"],"content":"\r8.3 安全(PKI)参考：安全 Docker内置了PKI，使保障发布容器化的业务流程系统的安全性变得很简单。Swarm节点之间采用TLS来鉴权、授权和加密通信。 当我们运行docker swarm init命令时，Docker指定当前节点为一个 manager 节点。默认情况下，manager 节点会生成一个新的根CA证书以及一对密钥。CA证书和密钥将会被用在节点之间的通信上。也可以通过参数–external-ca来指定其他CA证书。 Manager节点会生成两个token，一个用来添加worker节点，一个用来添加manager节点。每一个token包含了CA证书的digest和一个随机密钥。当节点加入到Swarm中时，加入的节点将digest发送给远端的manager节点，由manager节点来验证申请加入节点的根CA证书是否合法。远端manager节点通过随机密钥来验证申请加入的节点是否被核准加入。 每当节点加入到Swarm中后，manager都会给节点发送一个证书。这个证书中包含了一个随机生成的节点ID，用来标识这个证书通用名称下的节点，以及组织单元下的角色。在节点的当前Swarm生命周期中，节点ID是节点的安全加密的身份标识。 下图说明了manager节点和worker节点如何使用TSL 1.2进行通信加密的。 下面的例子展示了一个worker节点获得证书内容： bash Certificate: Data: Version: 3 (0x2) Serial Number: 3b:1c:06:91:73:fb:16:ff:69:c3:f7:a2:fe:96:c1:73:e2:80:97:3b Signature Algorithm: ecdsa-with-SHA256 Issuer: CN=swarm-ca Validity Not Before: Aug 30 02:39:00 2016 GMT Not After : Nov 28 03:39:00 2016 GMT Subject: O=ec2adilxf4ngv7ev8fwsi61i7, OU=swarm-worker, CN=dw02poa4vqvzxi5c10gm4pq2g ...snip...\r默认情况下，每个节点的证书3个月轮换一次。我们可以通过配置修改的这个间隔：docker swarm update –cert-expiry 。最小的证书轮换时间为1小时。 8.3.1 CA证书轮换如果Swarm的CA密钥或Manager节点受到危害，您可以轮换Swarm的根CA证书，以使所有节点都不再信任旧的根CA签名的证书。 运行命令docker swarm ca --ratate来生成新的CA证书和密钥。也可以通过参数--ca-cert和--external-ca来指定外部的根CA证书。 当运行了docker swarm ca --rotate命令后，会按顺序发生下面的事情： Docker会生成一个交叉签名（cross-signed）证书。即新证书是由旧的证书签署的。这个交叉签名证书将作为一个过渡性的证书。这是为了确保节点仍然能够信任旧的证书，也能使用新的CA证书验证签名。 在Docker 17.06或者更高版本中，Docker会通知所有节点立即更新TLS证书。根据Swarm中节点的数量多少，这个过程可能会花费几分钟时间。 注意：如果Swarm中的节点上Docker的版本不一致，将会发生下面的情况： 只有manager节点运行了Docker 17.06或者更高版本，并且作为leader时，才能通知到其他节点更新TLS证书。 只有Docker 17.06或者更高版本才会支持这个指令。 最好确保所有的Swarm节点上运行Docker 17.06或者更高版本。 在所有的节点都更新了新CA证书签署的TLS证书后，Docker将不在信任旧的证书，并通知所有节点仅信任新的CA证书。 加入Swarm使用的token将发生变化，旧的token将不可用。 从这时起，所有新的由新根CA证书签署的节点证书将颁发给节点，并且完全不存在过度内容。 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:3","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#831-ca证书轮换"},{"categories":["distributed system"],"content":"\r8.4 Task的状态Service是应用运行的理想状态的描述，task在这个理想状态下完成工作。工作按照下面的流程在Swarm节点之间被调度： 使用CLI运行命令docker service create，或者使用UCP web界面。 请求传递给manager节点。 manager节点在特定的节点调度service的运行。 每一个service可以由多个task来执行。 每一个task都有一个生命周期，生命周期的状态包括：NEW，PENDING和COMPLETE等等。 Task是一次执行单元。当task停止，就不会再被执行，除非一个新的task会取代它。 在task执行完成或者失败之前，task会通过一系列的状态变化。task由NEW状态初始化。task的状态变化过程是不可逆的。例如，一个task是永远不会从COMPLETE状态变回RUNNING状态的。 Task的状态如下表： 状态 描述 NEW 初始化状态 PENDING 资源分配了任务时的状态 ASSIGNED task被分配到节点后的状态 ACCEPTED task被worker节点接受后的状态。 PREPARING Docker正在准备task STARTING Docker启动task RUNNING 正在运行中的状态 COMPLETE task已经存在，并且没有错误码 FAILED task已经存在，但是有错误码出现 SHUTDOWN Docker被请求关闭task REJECTED worker节点拒绝接受task ORPHANED 节点离线时间超长 8.4.1 查看状态运行命令docker service ps \u003cservice-name\u003e来获得task的状态。CURRENT STATE表示task的状态： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:4","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#84-task的状态"},{"categories":["distributed system"],"content":"\r8.4 Task的状态Service是应用运行的理想状态的描述，task在这个理想状态下完成工作。工作按照下面的流程在Swarm节点之间被调度： 使用CLI运行命令docker service create，或者使用UCP web界面。 请求传递给manager节点。 manager节点在特定的节点调度service的运行。 每一个service可以由多个task来执行。 每一个task都有一个生命周期，生命周期的状态包括：NEW，PENDING和COMPLETE等等。 Task是一次执行单元。当task停止，就不会再被执行，除非一个新的task会取代它。 在task执行完成或者失败之前，task会通过一系列的状态变化。task由NEW状态初始化。task的状态变化过程是不可逆的。例如，一个task是永远不会从COMPLETE状态变回RUNNING状态的。 Task的状态如下表： 状态 描述 NEW 初始化状态 PENDING 资源分配了任务时的状态 ASSIGNED task被分配到节点后的状态 ACCEPTED task被worker节点接受后的状态。 PREPARING Docker正在准备task STARTING Docker启动task RUNNING 正在运行中的状态 COMPLETE task已经存在，并且没有错误码 FAILED task已经存在，但是有错误码出现 SHUTDOWN Docker被请求关闭task REJECTED worker节点拒绝接受task ORPHANED 节点离线时间超长 8.4.1 查看状态运行命令docker service ps 来获得task的状态。CURRENT STATE表示task的状态： ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:8:4","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#841-查看状态"},{"categories":["distributed system"],"content":"\r附：docker 命令参考docker 常用命令 Docker network命令 常用命令 Docker实践(二)：容器的管理(创建、查看、启动、终止、删除) ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:9:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#附docker-命令参考"},{"categories":["distributed system"],"content":"\r附：Raft 协议参考raft 是工程上使用较为广泛的强一致性、去中心化、高可用的分布式协议 参考 Raft 协议原理详解，10 分钟带你掌握 一文搞懂Raft算法 其他参考： 安装教程 01 安装教程 02 docker swarm集群创建、配置、可视化管理实验 Docker Swarm 管理节点高可用分析 使用swarm搭建和管理docker集群 Docker Swarm （容器集群，高可用，安全） Docker Swarm 深入浅出 DockerSwarm获取Token与常用命令 Portainer - Docker的可视化管理工具使用详解 Docker network命令 在 Swarm 集群中使用 Compose 文件 https://www.cnblogs.com/xiangsikai/p/9935253.html |PS：原《 docker 进阶》见 7.3 ","date":"2022-12-01","objectID":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/:10:0","series":null,"tags":["docker","swarm","distributed"],"title":"基于 Swarm 的 Docker 分布式集群管理","uri":"/%E5%9F%BA%E4%BA%8E-swarm-%E7%9A%84-docker-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/#附raft-协议参考"},{"categories":["linux"],"content":"\rlinux重定向可以将命令的输出或输入重新定向到其他位置或文件，以实现对输出输入的控制。默认情况下命令的输出通常为终端，如果想将输出转移到文件或其他位置，这时候就需要重定向。 文件描述符：一个命令通常都会打开三个文件，默认使用文件描述符0,1,2来指代这个三个文件 bash stdin 0 标准输入流 （键盘） stdout 1 标准输出流 （终端） stderr 2 标准错误输出流 （终端）\r以上标准输出和输入均在终端中进行，而重定向符 \u003e、\u003e\u003e 就是将其输出对象进行改变 shell 中常见重定向形式如下： bash \u003e file // 标准输出重定向到文件（覆盖） \u003e\u003e file // 标准输出重定向到文件（追加） 2\u003e file // 标准错误重定向到文件（覆盖） 2\u003e\u003e file // 标准错误重定向到文件（追加） 2\u003e /dev/null // 标准错误重定向到回收站 \u0026\u003e file // 标准输出和标准错误重定向到文件（覆盖） \u003e\u003e file 2\u003e\u00261 // 标准输出和标准错误重定向到文件（追加）\r默认的重定向为标准输出重定向，即 \u003e file 等价于 1\u003e file \u0026\u003e file 等价于 1\u003e file 2\u003e\u00261 ，这里的 \u00261 指的是标准输出 1 当格式为 \u003e\u003e file 2\u003e\u00261 不代表 标准输出追加而标准错误输出覆盖！ Linux ：输入/输出重定向 \u003e, 1\u003e, 2\u003e, \u0026\u003e, » , « linux 中的输入输出重定向（b 站） ","date":"2022-09-30","objectID":"/linux-%E9%87%8D%E5%AE%9A%E5%90%91/:0:0","series":null,"tags":["linux","redirection","重定向"],"title":"Linux 重定向","uri":"/linux-%E9%87%8D%E5%AE%9A%E5%90%91/#"},{"categories":["base-tool"],"content":"\r","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:0:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#"},{"categories":["base-tool"],"content":"\r1. Anaconda 与 Miniconda 与 Conda\rConda 维基：conda conda官网 任何语言的包、依赖项和环境管理 — Python、R、Ruby、Lua、Scala、Java、JavaScript、C/C++、FORTRAN 等。 Conda 是一个开源包管理系统和环境管理系统，在 Windows、macOS 和 Linux 上运行。Conda 快速安装、运行和更新包及其依赖项。Conda 可在本地计算机上轻松创建、保存、加载和切换环境。它是为 Python 程序创建的，但它可以打包和分发任何语言的软件。 Conda 作为包管理器可帮助您查找和安装包。如果需要不同版本的 Python 的包，则不需要切换到其他环境管理器，因为 conda 也是环境管理器。只需几个命令，就可以设置一个完全独立的环境来运行不同版本的 Python，同时在正常环境中继续运行通常版本的 Python。 conda 包和环境管理器包含在 Anaconda 和 Miniconda 的所有版本中。 以上为conda官网对于codna的说明，简单说就是包管理工具，并且提供设置不同的环境的功能，因此用户能在不同版本的python之间灵活切换，不同python环境各自独立。 Anaconda 维基：Anaconda Anaconda官网 Anaconda是一个免费开源的Python和R语言的发行版本，用于计算科学（数据科学、机器学习、大数据处理和预测分析），Anaconda致力于简化软件包管理系统和部署。Anaconda的包使用软件包管理系统Conda进行管理 以上为维基Anaconda词条，简单说来就是python的一个发行版本，包括python、conda、许多科学计算需要的包，以及一些科学计算用到的工具等 Minicona Miniconda官网 Miniconda 是conda的免费最小安装程序。这是一个小的，引导版本的Anaconda，只包括conda，Python，他们依赖的包，和少数其他有用的包，包括pip，zlib和其他一些。 以上为Miniconda官网的介绍 ","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:1:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#1-anaconda-与-miniconda-与-conda"},{"categories":["base-tool"],"content":"\r2. 下载与安装","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:2:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#2-下载与安装"},{"categories":["base-tool"],"content":"\r下载 下载Anaconda还是Miniconda？ 如果只是需要使用到不同的Python的环境，没有机器学习、科学计算等需求，下载Miniconda其实就行，需要一些包后续使用conda或pip安装即可。但是有些包因为版本问题等不是十分容易安装，而Anaconda自带很多常用、不常用的包，在这方面会比较方便。因此安装Anaconda肯定是没问题的，Anaconda安装包更大，并且自带Spyder、Jupyter等（安装后可删除），如果怕麻烦，电脑空间也够，那就安装Anaconda 如果有强迫症，讨厌捆绑很多东西(比如本人)，那自然…… Miniconda下载 官网 清华镜像 Anaconda下载 官网 清华镜像 官网下载速度可能比较慢，从清华镜像下载会快很多 ","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:2:1","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#下载"},{"categories":["base-tool"],"content":"\r安装Miniconda 与 Anaconda 安装界面类似 点击 next，点击I Agree，如下 Just Me安装在当前用户；All Users给所用用户安装。因为一台计算机中用户可能有多个(尽管Windows用户很多时候只有一个……)，给所有用户安装那只要是这台计算机中的用户都能使用Anaconda/Miniconda，Just Me就是只给当前所使用的用户安装~~（也不是说别的用户就完全不能用）~~，按个人喜好勾选，Windows个人还是建议All Users，毕竟多数时候是只是用一个用户的emmm 点击Next，之后选择安装路径， 点击Next 两个选择框选择环境变量的添加，第一个是添加环境变量，第二个是将Anaconda/Miniconda自带的Python作为系统的python 第一个个人建议勾选(不勾选之后再添加也可，网上有博客说勾选出问题了的，不过我是没出过问题哈，自己添加可参考下面安装完成后的环境变量，Anaconda与Miniconda类似)，第二个如果计算机还有其他Python根据情况选择，如果和其他Python产生冲突，之后调整环境变量顺序即可。 Install等待安装即可，都勾选安装完成后涉及Anaconda的环境变量如下 可以打开cmd(环境变量已经配好了)再验证下是否安装完成了 查看当前python版本（安装了其他版本python可在环境变量里看看顺序，在前面的优先） bash python -V\r查看conda版本 bash conda -V\r查看pip版本 bash pip -V\r启用base环境（Windows上，建议使用cmd，如果是使用cmd，提示符最前面会有base标记，Power shell的话没有） bash activate base\r","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:2:2","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#安装"},{"categories":["base-tool"],"content":"\r3. 换源使用conda更新、下载包时都比较慢，更换为国内源后会快很多 参看：国内可用Anaconda 源的镜像站及换国内源方法 添加清华源 命令行中直接使用以下命令（ubuntu命令行也可以） bash conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ # 设置搜索时显示通道地址 conda config --set show_channel_urls yes\r添加中科大源 bash conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/ conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/ conda config --set show_channel_urls yes\r","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:3:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#3-换源"},{"categories":["base-tool"],"content":"\r4. conda常用命令 查看conda版本，验证是否安装 bash conda --version 更新至最新版本，也会更新其它相关包 bash conda update conda\r更新所有包 bash conda update --all 更新指定的包 bash conda update package_name\r显示所有的虚拟环境 bash conda env list\r或者 bash conda info -e\r切换至env_name环境 bash conda activate env_name\r退出环境 bash codna deactivate\r创建名为env_name的新环境，并在该环境下安装名为package_name 的包，可以指定新环境的版本号，例如：conda create -n python2 python=python2.7 numpy pandas，创建了python2环境，python版本为2.7，同时还安装了numpy pandas包 bash conda create --name env_name package_name python=3.7\r--name可缩写为-n 查看所有已经安装的包 bash conda list\r在当前环境中安装包 bash conda install package_name\r在指定环境中安装包 bash conda install --name env_name package_name\r删除指定环境中的包 bash conda remove --name env_name package 删除当前环境中的包 bash conda remove package\r复制old_env_name为new_env_name bash conda create --name new_env_name --clone old_env_name\r删除环境 bash conda remove --name env_name --all\r清理 bash conda clean -p //删除没有用的包 conda clean -t //删除tar包 conda clean -y --all //删除所有的安装包及cache\rconda clean就可以轻松搞定！第一步：通过conda clean -p来删除一些没用的包，这个命令会检查哪些包没有在包缓存中被硬依赖到其他地方，并删除它们。第二步：通过conda clean -t可以将删除conda保存下来的tar包。 https://blog.csdn.net/zhayushui/article/details/80433768 复制/重命名/删除env环境 Conda是没有重命名环境的功能的, 要实现这个基本需求, 只能通过愚蠢的克隆-删除的过程。 切记不要直接mv移动环境的文件夹来重命名, 会导致一系列无法想象的错误的发生! 注意：必须在base环境下进行以上操作，否则会出现各种莫名的问题。 https://blog.csdn.net/zhayushui/article/details/80433768 bash //克隆oldname环境为newname环境 conda create --name newname --clone oldname //彻底删除旧环境 conda remove --name oldname --all\r","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:4:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#4-conda常用命令"},{"categories":["base-tool"],"content":"\r5. MindSpore相关MindSpore官网 MindSpore安装 ","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:5:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#5-mindspore相关"},{"categories":["base-tool"],"content":"\r6.jupyter notebook使用Jupyter Notebook 添加代码自动补全功能 ","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:6:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#6jupyter-notebook使用"},{"categories":["base-tool"],"content":"\r其他参考【1】conda常用命令 【2】conda常用命令:安装，更新，创建，激活，关闭，查看，卸载，删除，清理，重命名，换源，问题 ","date":"2022-06-24","objectID":"/conda-%E7%AE%80%E8%AE%B0/:7:0","series":null,"tags":["conda","anconda","miniconda","python"],"title":"Conda 简记","uri":"/conda-%E7%AE%80%E8%AE%B0/#其他参考"},{"categories":["base-tool"],"content":"\r","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:0:0","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#"},{"categories":["base-tool"],"content":"\r1. git 配置","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:1:0","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#1-git-配置"},{"categories":["base-tool"],"content":"\r1.1 git 三级配置 System： /etc/gitconfig，Msys64 底下的 etc Global： ~/.gitconfig，Msys64 底下的 home/[UserName]/w为 ~ 工程目录： .git/gitconfig 作用域依次减小，优先级依次升高 ps：不是安装 Msys64 而是Window 版的 git 在window用户家目录下会有文件.gitconfig bash git config --system --list # 查看系统配置 git config --global --list # 查看全局配置 git config --list # 查看所有配置 git config -l # 同上简写 git config --system -e # 直接打开系统配置 git config --global -e # 直接打开全局配置 git config -e # 直接打开项目配置\r注：git config --list 查看的是当前项目所有的配置（综合系统配置与全局配置和项目配置），不是仅仅查看的 .git 目录下的配置 ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:1:1","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#11-git-三级配置"},{"categories":["base-tool"],"content":"\r1.2 修改 git 配置通过上述命令查看用户名是否设置完成，没有需要进行设置 bash # 设置用户签名 git config --global user.name \"userName\" git config --global user.email \"userEmail\"\r用户名和邮件是必须要配置的！ 无论采用用户名+密码验证方式的 http，还是采用密钥验证的 ssh，在和远程仓库关联时均只是在做权限验证，即是否能往该远程库推送。但具体提交的修改需要记录是谁做的，因此 git 系统中需要配置用户名与邮件地址来在远程仓库记录下这些操作是由谁来完成的。 具体参考对给git配置邮箱和用户名的理解 除了设置全局签名，使用 git config user.name \"userName\" 来设置当前项目的签名也可以。 ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:1:2","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#12-修改-git-配置"},{"categories":["base-tool"],"content":"\r2. git 理论 工作区=》写代码 临时存储=》暂存区 历史版本=》本地库 工作区=》git add 添加到暂存区=》git commit本地库 只有在git commit进行提交到本地库后才有版本控制 ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:2:0","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#2-git-理论"},{"categories":["base-tool"],"content":"\r3. 项目中常用命令","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:3:0","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#3-项目中常用命令"},{"categories":["base-tool"],"content":"\r3.1 初始化、提交等\rbash git init # 初始化本地库\rbash git status # 查看本地库状态\r查看文件有没有被修改、追踪 bash git add fileName # 添加到缓存区 git add . # 添加当前目录所有文件进行追踪 git rm --cached fileName # 删除缓存区的文件\r没有被追踪文件/文件夹，存在工作区，通过 add 使其添加到缓存区 git 追踪的文件发生修改是绿色,没被追踪的文件发生修改是红色 通过 add 添加至缓冲区的文件能通过 git rm --cached 从缓冲区中删除，不再追踪。命令删除的是缓存区的文件，工作区的文件依旧存在的 ps：windows端git的bash里使用vim编辑文件后 add 命令会将LF转换成CRLF，但是msys2的不会 bash git diff # 查看具体修改地方\rbash git commit -m \"日志信息\" fileName # 提交本地库\rbash git reflog # 查看版本信息\rbash git log\rbash # 版本穿梭 git reset --hard 版本号\r示例如下： txt eg. C:\\Users\\yuqin\\Desktop\\git_demo\u003egit reflog 5341b98 (HEAD -\u003e master) HEAD@{0}: commit: second commit 326787f HEAD@{1}: commit (initial): first commit C:\\Users\\yuqin\\Desktop\\git_demo\u003egit reset --hard 326787f HEAD is now at 326787f first commit C:\\Users\\yuqin\\Desktop\\git_demo\u003egit reflog 326787f (HEAD -\u003e master) HEAD@{0}: reset: moving to 326787f 5341b98 HEAD@{1}: commit: second commit 326787f (HEAD -\u003e master) HEAD@{2}: commit (initial): first commit\r忽略特殊文件 txt # .gitignore # 忽略所有 .a 结尾的文件 *.a # 但 lib.a 除外 !lib.a # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO /TODO # 忽略 build/ 目录下的所有文件 build/ # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt doc/*.txt # ignore all .txt files in the doc/ directory doc/**/*.txt ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:3:1","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#31-初始化提交等"},{"categories":["base-tool"],"content":"\r分支相关\rbash git branch # 查看分支 git branch -r # 查看远程分支 git branch -a # 查看所有分支（包括远程） git branch \u003cname\u003e # 创建分支 git branch -d \u003cname\u003e # 删除分支 git checkout \u003cname\u003e # 切换分支 git branch -b \u003cname\u003e # 创建并切换 git switch \u003cname\u003e # 切换分支 git switch -c \u003cname\u003e # 创建并切换 git merge \u003cname\u003e # 合并分支\r例如，在 master 分支中使用 git merge dev 命令，则会将 dev 分支的更新内容合并至 master 分支。 在 idea 中，直接从右下角找到 dev 分支，选择 Merge dev into master 即可。 ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:3:2","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#分支相关"},{"categories":["base-tool"],"content":"\r3.2 克隆远程库\rbash # https 协议下载 git clone https://gitee.com/yuqinlee/test.git # ssh 协议下载 git clone git@gitee.com:liaoxuefeng/learngit.git # 本地没有项目，直接拉取指定分支 git clone -b dev git@gitee.com:liaoxuefeng/learngit.git # 本地已经有项目 git fetch --all # 先更新 git checkout -b dev origin/dev # 在拉取\r使用 git clone 命令下载远程库后，会自带版本信息 clone、fetch、pull区别： clone：远程克隆仓库，带版本控制 fetch：从远程获取最新版本到本地，不会自动merge pull：从远程获取最新版本并merge到本地仓库 ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:3:3","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#32-克隆远程库"},{"categories":["base-tool"],"content":"\r3.3 关联远程库\rbash # http 协议关联 git remote add origin https://gitee.com/yuqinlee/test.git # ssh 协议关联 git remote add origin git@gitee.com:liaoxuefeng/learngit.git\r取消关联远程仓库 bash git remote remove origin\r将本地分支关联到远程分支 bash git branch --set-upstream-to=origin/develop develop\r","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:3:4","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#33-关联远程库"},{"categories":["base-tool"],"content":"\r3.4 同步\rbash git push -u origin \"master\" # 推送\r远程关联仓库（gitee 示例） Git 全局设置: bash git config --global user.name \"yuqinlee\" git config --global user.email \"yuqin.lee@outlook.com\"\r创建 git 仓库: bash mkdir test cd test git init touch README.md git add README.md git commit -m \"first commit\" # git remote add origin https://gitee.com/yuqinlee/test.git git remote add origin git@gitee.com:liaoxuefeng/learngit.git git push -u origin \"master\" # 指定本地 dev 分支与远程 origin/dev 分支的链接，根据提示，设置dev和 origin/dev 的链接 git branch --set-upstream-to=origin/dev dev\r已有仓库? bash cd existing_git_repo git remote add origin https://gitee.com/yuqinlee/test.git git push -u origin \"master\"\r参考 Git 原理入门 - 阮一峰的网络日志 (ruanyifeng.com) 5.git添加远程仓库,再克隆到本地,然后做分支管理 廖雪峰 git 教程 git clone、git pull和git fetch的用法及区别 对给git配置邮箱和用户名的理解 https://www.bilibili.com/video/BV1FE411P7B3?spm_id_from=..search-card.all.click git 学习记录—— git 中的仓库、文件状态等概念介绍 lh-常用Git命令总结 代码同时更新到Gitee和github 注：使用Msys2的git vscode会有问题 ","date":"2022-01-24","objectID":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/:3:5","series":null,"tags":["git"],"title":"Git 使用小结","uri":"/git-%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/#34-同步"},{"categories":["distributed"],"content":"\r2020-11-04 https://www.bilibili.com/video/av37065233 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:0:0","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#"},{"categories":["distributed"],"content":"\r一、BTC-密码学原理","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:1:0","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#一btc-密码学原理"},{"categories":["distributed"],"content":"\r1. Hash\r性质1 collision resistance密文m H(m)经过hash函数处理之后得到一个hash值，很难在修改m后再进行hash运算还是原来的值，尽管存在hash碰撞 没有证明那个hash函数是不存在collision resistance的！！但是有函数是被验证是能够人为找出碰撞的，如MD5 性质2 hidinghiding：hash函数的计算是单向且不可逆的，即给定x，可以算出其hash值$H(x)$ , $x-\u003eH(x)$但是没办法从$H(x)$反推出$x$ hiding成立的前提是输入空间足够大(不然直接暴力遍历出原文),并且输入的取值比较均匀,各种取值差不多 hiding与collision resistance结合起来,实现 digital commitment(digital equivalent of a sealed envelope) 例如,呀进行股市的预测,需提前给出预测,但是又不能将结果直接公布,因为这个预测会对结果产生影响,所以,可以先将预测进行hash,得到一个hash值,由于性质1与性质2,在第二天结果知晓后,公布预测内容并计算hash值,对比之前公布的hash值,相同则预测正确 实际操作中,为使输入的空间足够大,可以$H(x||nonce)$,即在输入内容后增加一个随机数(nonce) 性质3 puzzle friendlypuzzle friendly:hash值的计算事先是不可预测的,即如果想获得一个区间范围内的hash值,那只能一个一个试 例如,想要获得一个经过hash运算后，256位的hash值是形如\"00……00xxxxx\"前k位都是\"0\"的原文，那只能一个一个试，而没有方法实现知道。在挖矿中，$nonce$在$block\\quad header$中,是可以自己设置的,挖矿过程就是找到适合的$nonce$使得满足以下式子: $$ H(block\\quad header)\\leq target $$ $H(block\\quad header)$要落在指定的$target\\quad space$中,只有经过大量的尝试,才能证明其中的\"$proof\\quad of\\quad work$\",在这个过程中,“挖矿\"是很难的,但是去验证是很容易的,这个性质叫**“difficult to solve,but easy to verify”** 在比特币中使用的hash函数是$SHA-256(Secure Hash Algorithm)$,满足上述三个性质 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:1:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#1-hash"},{"categories":["distributed"],"content":"\r1. Hash\r性质1 collision resistance密文m H(m)经过hash函数处理之后得到一个hash值，很难在修改m后再进行hash运算还是原来的值，尽管存在hash碰撞 没有证明那个hash函数是不存在collision resistance的！！但是有函数是被验证是能够人为找出碰撞的，如MD5 性质2 hidinghiding：hash函数的计算是单向且不可逆的，即给定x，可以算出其hash值$H(x)$ , $x-\u003eH(x)$但是没办法从$H(x)$反推出$x$ hiding成立的前提是输入空间足够大(不然直接暴力遍历出原文),并且输入的取值比较均匀,各种取值差不多 hiding与collision resistance结合起来,实现 digital commitment(digital equivalent of a sealed envelope) 例如,呀进行股市的预测,需提前给出预测,但是又不能将结果直接公布,因为这个预测会对结果产生影响,所以,可以先将预测进行hash,得到一个hash值,由于性质1与性质2,在第二天结果知晓后,公布预测内容并计算hash值,对比之前公布的hash值,相同则预测正确 实际操作中,为使输入的空间足够大,可以$H(x||nonce)$,即在输入内容后增加一个随机数(nonce) 性质3 puzzle friendlypuzzle friendly:hash值的计算事先是不可预测的,即如果想获得一个区间范围内的hash值,那只能一个一个试 例如,想要获得一个经过hash运算后，256位的hash值是形如\"00……00xxxxx\"前k位都是\"0\"的原文，那只能一个一个试，而没有方法实现知道。在挖矿中，$nonce$在$block\\quad header$中,是可以自己设置的,挖矿过程就是找到适合的$nonce$使得满足以下式子: $$ H(block\\quad header)\\leq target $$ $H(block\\quad header)$要落在指定的$target\\quad space$中,只有经过大量的尝试,才能证明其中的\"$proof\\quad of\\quad work$\",在这个过程中,“挖矿\"是很难的,但是去验证是很容易的,这个性质叫**“difficult to solve,but easy to verify”** 在比特币中使用的hash函数是$SHA-256(Secure Hash Algorithm)$,满足上述三个性质 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:1:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#性质1-collision-resistance"},{"categories":["distributed"],"content":"\r1. Hash\r性质1 collision resistance密文m H(m)经过hash函数处理之后得到一个hash值，很难在修改m后再进行hash运算还是原来的值，尽管存在hash碰撞 没有证明那个hash函数是不存在collision resistance的！！但是有函数是被验证是能够人为找出碰撞的，如MD5 性质2 hidinghiding：hash函数的计算是单向且不可逆的，即给定x，可以算出其hash值$H(x)$ , $x-\u003eH(x)$但是没办法从$H(x)$反推出$x$ hiding成立的前提是输入空间足够大(不然直接暴力遍历出原文),并且输入的取值比较均匀,各种取值差不多 hiding与collision resistance结合起来,实现 digital commitment(digital equivalent of a sealed envelope) 例如,呀进行股市的预测,需提前给出预测,但是又不能将结果直接公布,因为这个预测会对结果产生影响,所以,可以先将预测进行hash,得到一个hash值,由于性质1与性质2,在第二天结果知晓后,公布预测内容并计算hash值,对比之前公布的hash值,相同则预测正确 实际操作中,为使输入的空间足够大,可以$H(x||nonce)$,即在输入内容后增加一个随机数(nonce) 性质3 puzzle friendlypuzzle friendly:hash值的计算事先是不可预测的,即如果想获得一个区间范围内的hash值,那只能一个一个试 例如,想要获得一个经过hash运算后，256位的hash值是形如\"00……00xxxxx\"前k位都是\"0\"的原文，那只能一个一个试，而没有方法实现知道。在挖矿中，$nonce$在$block\\quad header$中,是可以自己设置的,挖矿过程就是找到适合的$nonce$使得满足以下式子: $$ H(block\\quad header)\\leq target $$ $H(block\\quad header)$要落在指定的$target\\quad space$中,只有经过大量的尝试,才能证明其中的\"$proof\\quad of\\quad work$\",在这个过程中,“挖矿\"是很难的,但是去验证是很容易的,这个性质叫**“difficult to solve,but easy to verify”** 在比特币中使用的hash函数是$SHA-256(Secure Hash Algorithm)$,满足上述三个性质 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:1:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#性质2-hiding"},{"categories":["distributed"],"content":"\r1. Hash\r性质1 collision resistance密文m H(m)经过hash函数处理之后得到一个hash值，很难在修改m后再进行hash运算还是原来的值，尽管存在hash碰撞 没有证明那个hash函数是不存在collision resistance的！！但是有函数是被验证是能够人为找出碰撞的，如MD5 性质2 hidinghiding：hash函数的计算是单向且不可逆的，即给定x，可以算出其hash值$H(x)$ , $x-\u003eH(x)$但是没办法从$H(x)$反推出$x$ hiding成立的前提是输入空间足够大(不然直接暴力遍历出原文),并且输入的取值比较均匀,各种取值差不多 hiding与collision resistance结合起来,实现 digital commitment(digital equivalent of a sealed envelope) 例如,呀进行股市的预测,需提前给出预测,但是又不能将结果直接公布,因为这个预测会对结果产生影响,所以,可以先将预测进行hash,得到一个hash值,由于性质1与性质2,在第二天结果知晓后,公布预测内容并计算hash值,对比之前公布的hash值,相同则预测正确 实际操作中,为使输入的空间足够大,可以$H(x||nonce)$,即在输入内容后增加一个随机数(nonce) 性质3 puzzle friendlypuzzle friendly:hash值的计算事先是不可预测的,即如果想获得一个区间范围内的hash值,那只能一个一个试 例如,想要获得一个经过hash运算后，256位的hash值是形如\"00……00xxxxx\"前k位都是\"0\"的原文，那只能一个一个试，而没有方法实现知道。在挖矿中，$nonce$在$block\\quad header$中,是可以自己设置的,挖矿过程就是找到适合的$nonce$使得满足以下式子: $$ H(block\\quad header)\\leq target $$ $H(block\\quad header)$要落在指定的$target\\quad space$中,只有经过大量的尝试,才能证明其中的\"$proof\\quad of\\quad work$\",在这个过程中,“挖矿\"是很难的,但是去验证是很容易的,这个性质叫**“difficult to solve,but easy to verify”** 在比特币中使用的hash函数是$SHA-256(Secure Hash Algorithm)$,满足上述三个性质 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:1:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#性质3-puzzle-friendly"},{"categories":["distributed"],"content":"\r2. 签名$asymmetric\\quad encryption\\quad algorithm(非对称加密)$ 在现实中开户需要到银行进行相关手续，但是比特币开户只需要在本地创建一对公钥与私钥即可$(public\\quad key ,private\\quad key)$,知道公钥就相当于知道银行账号,其他人可以往里转账,而私钥就好比是账户的口令,能将账户中的\"钱\"取出来。比特币是不加密的加密货币，这里公私钥是为了进行签名。 会不会两人生成的公私钥对是相同的？答：可能性微乎其微 这里生成公私钥要求有一个$a\\quad good\\quad source\\quad of\\quad randomness$，如果随机源选择不好的话就有可能两个人的公私钥相同了；在比特币中，除了生成公私钥对时需要一个好的随机源，在每一次加密的过程中都需要有好的随机源，不然可能泄露私钥 比特币中一般是先对message进行hash，然后再对hash值进行签名！！ 区块链技术与应用——BTC密码学原理 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:1:2","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#2-签名"},{"categories":["distributed"],"content":"\r二、BTC-数据结构","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:2:0","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#二btc-数据结构"},{"categories":["distributed"],"content":"\rhash pointer、区块链普通指针是存储一个结构体的地址值，而hash指针除了存储地址值外还存储hash值，这样一来可以找到该结构体的位置，二来可以知道该结构体是否被改变，一般使用$H()$表示 比特币中区块与普通的区块的一个区别就是使用hash指针代替了普通指针 $Block\\quad chain\\quad is\\quad a\\quad linked\\quad list\\quad using\\quad hash\\quad pointers$ 后面一个hash值是将前面区块$block\\quad header$整个取hash，包括其中的hash function，以此实现了 tamper-evident log，这样如果前一个区块中的内容发生改变，那么后面的hash值也会发生改变，依次类推，后面所有的区块内容都会发生改变，所以只要记住最后的hash值就可以检测出整个区块链中任何部位的修改，这也是和普通区块的不同。 本地不必存储所有的区块，在需要使用前面的区块时向其他节点要即可，验证真伪只需要将前面的hash值进行对比就可。 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:2:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#hash-pointer区块链"},{"categories":["distributed"],"content":"\rMerkel tree 两个data blocks的hash pointer放在父节点，这两个hash pointer组合再取hash值，构成整个父节点，两个父节点的的hash pointer再放在更上一层中，…… binary tree与Merkel tree的区别 merkel tree使用hash指针代替了原有指针 只要记录root hash值，就能检测出对树中任何部位的修改 每个data block都是一个“交易” 比特币中各个区块之间用hash 指针连接在一起，每个区块所包含的交易是组织成一个Merkel tree的形式 每个区块分为$block\\quad header$和$block\\quad body$，在$block\\quad header$中有根hash值，而没有交易的具体内容，$block\\quad body$中是有交易列表的 merkel tree的作用：提供Merkel proof，示意图如下： 轻节点向全节点进行一个Merkel proof的请求，全节点向轻节点发送红色的H() 轻节点在本地根据待证明tx可以计算出其上一个绿色H()，而红色的H()是向全节点请求能得到的，因此和红色H()结合能算出再上一层的绿色H()，……最后能算出一个根hash值 此时与轻节点所保存的根hash值进行比较就可以验证是否待证明的tx交易在整个区块链中 以上证明称为$proof\\quad of\\quad membership$或$proof\\quad of\\quad inclusion$，其事件复杂度为$O(log(n))$,如果是证明$proof\\quad of\\quad no-membership$,其中一个方式是将整棵Merkel tree传回来，验证每一层的hash值都是正确的，则说明这树中只有这些叶节点，而没有待验证的此时复杂度为$O(n)$,如果没有对叶节点进行排序等操作，是没有更好的办法的，但是将tx按照交易的hash值进行排序，就能以$O(log(n))$的代价进行验证了，此时这棵树叫$sorted\\quad merkel\\quad tree$,在比特币中是没有这种需求的！ 没有环的数据结构中，hash pointer基本都可以代替普通指针，但是有环的是不行的 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:2:2","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#merkel-tree"},{"categories":["distributed"],"content":"\r三、BTC-协议前言 数字货币方案1 假设央行发行数字货币，只采用非对称密码，央行保存私钥，并用私钥进行数字签名，这样发行出来的货币存在的问题：“double spending attack”，即可以将央行发行的数字货币进行复制，从而进行多次支付！这也是数字货币面临的主要挑战。 数字货币方案2 在之前的基础上为每个数字货币添加一个编号，央行对编号的所有者进行记录，同时在完成支付之后更改编号所有者。这样就能防范“double spending attack ”。 这套方案可行，但每笔交易都经过央行，过于繁琐，这是一种中心化的方案。 简单区块链示意 上图中有两种hash指针，一种是区块链之间的连接的hash指针(橙色)，另一种是指向前面某个交易的(绿色) 比特币系统中每个交易都包含输入和输出两个部分: 输入：①说明币的来源；②A的公钥是什么 输出：给出收款人的公钥的hash 为什么要记录来源？①证明这个钱不是凭空捏造的；②防止double spending attack 例如上图中：B已经将钱转给C和D了，现在出现F，B要将钱再次转给F 别的节点收到交易后，从B转向F的交易向前查询，当查到B转给C与D时就会出生问题，B在转给C与D的这次交易中就已将5个币花了出去，即说明B转给F的交易是不合法的！！ 上述转账中，A转账给B，A需要的信息有： A的签名 B的地址（比特币中收款的地址通过公钥推算出来，公钥取hash经过一些转换得到） 比特币系统是不会提供查询某个人的地址的服务的，想要知道别人的地址，需要通过其他渠道，例如在某支持比特币的购物网站上，收款人可以贴出自己的地址/公钥。 上述转账中B、乃至所有的节点还需要知道A的公钥，因为B要知道支付人的信息，才能知道这笔交易的钱是从哪来的，同时A支付这一过程中A进行了签名，要验证签名就需要A的公钥（签名是私钥签，公钥验证）。A在交易的输入中就会说明A的公钥是什么。 问题：自己宣称公钥是否有漏洞？ 如果存在B的同伙$B’$,这时候伪造一个A到B的转账交易，$B’$用自己的公钥在输入中说是A的公钥，用自己的私钥进行签名，当别的节点用假造的公钥去验证交易的合法性，就会盗走A账户的钱？ 解决方式： 在Create Coin过程的输出中包含着A的公钥的hash，在交易A向B转账时，A的公钥要和之前的输出过程的hash对得上才行 示意图中每个区块包含着一个交易，但实际过程中每个区块中包含着许多交易，这些交易组装成Merkel Tree，每个区块分为$Block\\quad header$与$Block\\quad body$两个部分。 $Block\\quad header$包含着区块中的宏观信息: 使用的是比特币哪个版本的协议(version) 执行前一个区块的指针(hash of previous block header) 前一个区块的hash只算的是$block\\quad header$！！ 只有block header才有hash指针串联起来，每次取hash都是将块头进行取hash 因为Merkel root hash就能保证Block body中的交易列表是没有办法进行改变的。（因为要是改变了那header的hash值就会发生变化） 整个Merkel tree的根hash值(Merkel root hash) 难度目标阈值(target) 随机数(nonce) $$ H(block\\quad header)\\leq target $$ $block\\quad header$的hash值要小于target ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:3:0","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#三btc-协议"},{"categories":["distributed"],"content":"\r关于full node（全节点）与light node（轻节点）full node：也称fully validating node，保存全部信息 light node：只保存block header的信息，一般是无法独立验证交易的合法性的。轻节点知识利用区块链的信息进行一些查询等操作。 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:3:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#关于full-node全节点与light-node轻节点"},{"categories":["distributed"],"content":"\r比特币中的共识协议（Consensus in BitCoin） 账本的内容要取得分布式共识 distributed consensus FLP impossibility result： 在异步式系统（网络传输时延没有上限）中，只有一个成员有问题，也不可能取得共识 CAP Theorem：CAP三个性质中最多只能满足两个（见分布式系统） 共识协议要解决的问题：有些节点可能是有恶意的，这里假设系统中大多数节点是没有恶意的，有恶意的只是少数 **假想：**投票机制，某个节点提出一个候选区块，根据收到的交易信息，选择那些交易是合法的，将这些交易打包到区块里，将这个候选区块发布给所有节点，每个节点收到这个区块后检查一下是不是每个交易都是合法的，都合法就投赞成票，有一个交易是非法的就投反对票，赞成过半就写入区块链中 存在的问题： 提出候选区块的节点恶意加入非法区块到候选区块，并不断提交这种带非法交易的候选区块，造成一直投票却无法写入区块链 无法保证每个节点都投票 效率问题、网络还有延迟 比特币系统中，投票权问题无法确定，只要恶意产生足够多账户，超过半数，就可操作结果 （$sybil\\quad attack$） 在比特币中也是进行“投票”，但是是利用算力进行投票，每个节点都可以在本地组装出候选区块，将其认为合法的交易放到这个区块中，然后尝试各种nonce值，如果某个节点找到了nonce，使得$H(block\\quad header)\\leq target$,则该节点获得了记账权，即能往账本中写入下一个区块的权利。其他节点则检查是否符合要求。 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:3:2","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#比特币中的共识协议consensus-in-bitcoin"},{"categories":["distributed"],"content":"\r最长合法链下图中，区块1为C转账A，区块3为A转B，区块5为A再次转给自己，首先，这没有构成$double\\quad spending\\quad attack$,因为在链1\u003c-2\u003c-5中，A并没有使用两次，检测是否是”双花“时是不会检查其他链上的交易情况的。下图中5写到2的后面的情况显然是不被希望的。 因此在比特币协议中，规定写在**最长合法链**之后的才是合法区块,上述例子称为”forking attack（分叉攻击）“，即：通过往区块链中间某个区块后插入区块实现回滚某个已经发生了的交易。 在正常情况下，如果两个节点同时找到了合适的nonce并发布出去，由于整个系统中节点众多，不同节点认同的这两个区块中的某一个，那么就会形成两个等长的链，按照最长合法链原则，这两个都是合法的，比特币系统中，接受某个区块就会往该区块后面继续添加区块，因此会存在临时的分支，但某条链最后会”胜出“。 如上图，5，6同时发布，原先最长链分叉，这时形成两条合法链，如果在下一时刻，区块5后增加区块7，而6后并未增加新的区块，那么6所在的那条链就会被丢弃，称为”orphan block“。在”orphan block“中获得的block reward是不会被认可的 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:3:3","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#最长合法链"},{"categories":["distributed"],"content":"\rblock reward（出块奖励）去中心化货币面临的两个问题：①谁来发行货币；②怎么保证交易的合法性 coinbase transaction是发行比特币的唯一方法。 前21万个区块里，每个区块发行50BTC，之后21万区块里，每个区块发行25BTC，下一21万区块中，每个区块发行12.5BTC 50BTC -\u003e 25BTC -\u003e 12.5BTC -\u003e …… **hash rate：**比特币系统中根据算力投票，不同区块获取符合nonce的概率是不同的，这个称为hash rate 针对“sybil attack”，由于投票权是以算力决定的，即使创建账户十分多，也无法改变其算力大小。 区块链技术与应用——BTC的共识协议 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:3:4","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#block-reward出块奖励"},{"categories":["distributed"],"content":"\rBTH-实现比特币采用的是基于交易的账本模式，transaction-based ledger。 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:4:0","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#bth-实现"},{"categories":["distributed"],"content":"\rUTXO：Unspend Transaction Output即：还没有被花出去的交易的输出，区块链上有很多交易，有些交易的输出可能已经被花掉了，有些还没有被花掉，没有被花掉的交易的输出组成的集合就是UTXO。UTXO为比特币系统中的一个数据结构。 例如：A转给B、C各5BTC，这时B将这5个比特币花掉了，C没有花掉，那么就只有A与C的输出在UTXO中 如果这时B再转给D，D也没有花掉，那么B转给D的输出就会保存在UTXO UTXO中的每个元素要给出产生这个输出的交易的hash值，以及它在这个交易里是第几个输出，就可以定位到UTXO中的输出 为什么要维护UTXO这个数据结构？ 花掉的币只有在UTXO这个集合中才是合法的，如果不在这个集合中，那么花的币要么不存在，要么以前已经被花过了。全节点要在内存中维护UTXO这个数据结构，以便快速检测“double spending” total inputs=total outputs：一笔交易可以有多个输入（不一定来自同一个地址，所以一个交易也可能有多个签名），也可以有多个输出，要求交易的总输入等于总输出。 但有时total inputs 可能稍微大于outputs，因为还要给打包区块的节点提供费用，即$transaction\\quad fee（交易费）$。一般交易费是比较小的，甚至有的交易没有交易费。 为什么有交易费？ 光有出块奖励机制还不够，有些“自私”的节点可能只去打包自己的交易，而不去管别人的交易，因为打包别人的交易还要验证交易的合法性，占用带宽等，，显然只打包自己的会方便很多，因此交易会提供费用给打包的人。 目前挖矿主要还是为了获得出块奖励，规定约10min出一个区块，出21万个区块就减半，因此出块奖励大约4年就减半。在很长时间之后出块奖励会变得非常小，那么交易费就会成主要奖励来源了 $$ T_{减半周期}=\\frac {21000010min}{60min24h*365d}=3.995433 $$ 与比特币这种$transaction-based\\quad ledger$相对应的还有一种$account-based(基于账户的)\\quad ledger$,以太坊就是用的此模式，这种模式下，系统显示记录每个账户上有多少个币。两种方式各有优缺点，前者显然隐私的保护会更好，但是代价就是要说明币的来源。 创建时间：2020-11-04 修改时间：2020-11-08 ","date":"2020-11-04","objectID":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/:4:1","series":null,"tags":["block chain","distributed system","encryption"],"title":"区块链与安全Note","uri":"/%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%8E%E5%AE%89%E5%85%A8note/#utxounspend-transaction-output"}]